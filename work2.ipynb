{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b182c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Servidor GraphQL de Raphtory en marcha.\n",
      "Accede desde tu navegador a: http://localhost:1736\n"
     ]
    }
   ],
   "source": [
    "# ------------------ BLOQUE: INICIAR SERVIDOR RAPHTORY Y ACCEDER AL GRAFO ------------------\n",
    "from raphtory.graphql import GraphServer\n",
    "import time\n",
    "\n",
    "# Lanza el servidor GraphQL en la carpeta donde guardaste el grafo\n",
    "server = GraphServer(work_dir=\"graphs/\").start()\n",
    "client = server.get_client()\n",
    "\n",
    "\n",
    "\n",
    "print(\"🚀 Servidor GraphQL de Raphtory en marcha.\")\n",
    "print(\"Accede desde tu navegador a: http://localhost:1736\")\n",
    "\n",
    "# El nombre/path de tu grafo es: kiali_fullnode_graph-3\n",
    "# En la UI GraphQL puedes hacer queries, explorar nodos, aristas y ver todas las propiedades cargadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbd0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grafo de creación de microservicios guardado en: graphs/microservices_creation_graph\n"
     ]
    }
   ],
   "source": [
    "# Para unir comunicacion y creación\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from raphtory import Graph\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Cargar dataset\n",
    "csv_path = \"./results/final2_modified_sorted.csv\"\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"])\n",
    "\n",
    "# Crear grafo\n",
    "g = Graph()\n",
    "\n",
    "# Nombre del grafo y ruta\n",
    "graph_name = \"microservices_creation_graph\"\n",
    "output_path = f\"graphs/{graph_name}\"\n",
    "if os.path.exists(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "os.makedirs(\"graphs\", exist_ok=True)\n",
    "\n",
    "# Obtener el primer timestamp en que aparece cada microservicio\n",
    "first_appearances = df.sort_values(\"timestamp\").groupby(\"Microservice\").first().reset_index()\n",
    "\n",
    "# Crear nodos con marca temporal y conexión al pod\n",
    "for _, row in first_appearances.iterrows():\n",
    "    ts = int(row[\"timestamp\"].timestamp() * 1000)\n",
    "    ms = row[\"Microservice\"]\n",
    "    pod = row[\"pod\"]\n",
    "    abnormal_class = row[\"Abnormality class\"]\n",
    "\n",
    "    label = \"anomalous\" if abnormal_class != 1 else \"normal\"\n",
    "    color = \"red\" if label == \"anomalous\" else \"green\"\n",
    "\n",
    "    g.add_node(ts, ms, node_type=\"Microservice\", properties={\n",
    "        \"label\": label,\n",
    "        \"ui_color\": color\n",
    "    })\n",
    "\n",
    "    g.add_node(ts, pod, node_type=\"Pod\")\n",
    "\n",
    "    g.add_edge(ts, ms, pod, properties={\n",
    "        \"relationship\": \"deployed_to\",\n",
    "        \"label\": \"connects\"\n",
    "    })\n",
    "\n",
    "# Guardar grafo\n",
    "g.save_to_file(output_path)\n",
    "print(\"\\u2705 Grafo de creación de microservicios guardado en:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76df2532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_workload', 'destination_workload', 'timestamp', 'total_request',\n",
      "       'new_request', 'success_count', 'error_count', 'success_rate',\n",
      "       'error_rate', 'average_latency', 'istio_request_bytes', 'throughput',\n",
      "       'request_rate', 'time_window', 'link_color', 'Abnormality class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    " # ------------------ BLOQUE: VER COLUMNAS ------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV\n",
    "df = pd.read_csv('./results/kiali_kpi_metrics_processed.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714d6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvis in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from pyvis) (8.35.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyvis) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyvis) (4.1.0)\n",
      "Requirement already satisfied: networkx>=1.11 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyvis) (3.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis) (4.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=5.3.0->pyvis) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=5.3.0->pyvis) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=5.3.0->pyvis) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb99955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grafo completo con nodos y enlaces etiquetados y coloreados guardado en: graphs/microservices_graph_enriched\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from raphtory import Graph\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Cargar CSV principal\n",
    "df = pd.read_csv('./results/kiali_kpi_metrics_processed.csv', parse_dates=[\"timestamp\"])\n",
    "\n",
    "# Crear grafo\n",
    "g = Graph()\n",
    "\n",
    "# Nombre del grafo y ruta\n",
    "graph_name = \"microservices_graph_enriched\"\n",
    "output_path = f\"graphs/{graph_name}\"\n",
    "if os.path.exists(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "os.makedirs(\"graphs\", exist_ok=True)\n",
    "\n",
    "# Crear nodos y aristas con propiedades temporales\n",
    "for _, row in df.iterrows():\n",
    "    ts = int(row[\"timestamp\"].timestamp() * 1000)\n",
    "    src = row[\"source_workload\"]\n",
    "    dst = row[\"destination_workload\"]\n",
    "    abnormal_class = row[\"Abnormality class\"]\n",
    "\n",
    "    # Etiqueta y color del nodo\n",
    "    label = \"normal\" if abnormal_class == 1 else \"anomalous\"\n",
    "    color = \"green\" if abnormal_class == 1 else \"red\"\n",
    "\n",
    "    # Propiedades comunes de nodos\n",
    "    common_props = {\n",
    "        \"success_rate\": row[\"success_rate\"],\n",
    "        \"error_rate\": row[\"error_rate\"],\n",
    "        \"request_rate\": row[\"request_rate\"],\n",
    "        \"throughput\": row[\"throughput\"],\n",
    "        \"success_count\": row[\"success_count\"],\n",
    "        \"error_count\": row[\"error_count\"],\n",
    "        \"Abnormality_class\": abnormal_class,\n",
    "        \"time_window\": row[\"time_window\"]\n",
    "    }\n",
    "\n",
    "    # Añadir nodos\n",
    "    g.add_node(ts, src, properties=common_props, node_type=\"Microservice\")\n",
    "    g.add_node(ts, dst, properties=common_props, node_type=\"Microservice\")\n",
    "\n",
    "    # Etiqueta y color del edge\n",
    "    edge_label = \"normal_link\" if abnormal_class == 1 else \"anomalous_link\"\n",
    "    edge_color = \"green\" if abnormal_class == 1 else \"red\"\n",
    "\n",
    "    # Arista con props visuales y métricas\n",
    "    edge_props = {\n",
    "        \"average_latency\": row[\"average_latency\"],\n",
    "        \"total_request\": row[\"total_request\"],\n",
    "        \"new_request\": row[\"new_request\"],\n",
    "        \"istio_request_bytes\": row[\"istio_request_bytes\"],\n",
    "        \"Abnormality_class\": abnormal_class,\n",
    "        \"link_color\": row.get(\"link_color\", edge_color),  # se prioriza la columna si existe\n",
    "        \"relationship\": \"communicates\",\n",
    "        \"label\": edge_label,\n",
    "        \"ui_color\": edge_color\n",
    "    }\n",
    "\n",
    "    g.add_edge(ts, src, dst, properties=edge_props)\n",
    "\n",
    "# Guardar grafo\n",
    "g.save_to_file(output_path)\n",
    "print(\"✅ Grafo completo con nodos y enlaces etiquetados y coloreados guardado en:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a23102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grafo completo con nodos y enlaces etiquetados y coloreados guardado en: graphs/microservices_graph_enriched_temporal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from raphtory import Graph\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Cargar CSV principal\n",
    "df = pd.read_csv('./results/kiali_kpi_metrics_processed.csv', parse_dates=[\"timestamp\"])\n",
    "\n",
    "# Crear grafo\n",
    "g = Graph()\n",
    "\n",
    "# Nombre del grafo y ruta\n",
    "graph_name = \"microservices_graph_enriched_temporal\"\n",
    "output_path = f\"graphs/{graph_name}\"\n",
    "if os.path.exists(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "os.makedirs(\"graphs\", exist_ok=True)\n",
    "\n",
    "# Crear nodos y aristas con propiedades temporales\n",
    "added_edges = set()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ts = int(row[\"timestamp\"].timestamp() * 1000)\n",
    "    src = row[\"source_workload\"]\n",
    "    dst = row[\"destination_workload\"]\n",
    "    abnormal_class = row[\"Abnormality class\"]\n",
    "\n",
    "    # Etiqueta y color del nodo\n",
    "    label = \"normal\" if abnormal_class == 1 else \"anomalous\"\n",
    "    color = \"green\" if abnormal_class == 1 else \"red\"\n",
    "\n",
    "    # Propiedades comunes de nodos\n",
    "    common_props = {\n",
    "        \"success_rate\": row[\"success_rate\"],\n",
    "        \"error_rate\": row[\"error_rate\"],\n",
    "        \"request_rate\": row[\"request_rate\"],\n",
    "        \"throughput\": row[\"throughput\"],\n",
    "        \"success_count\": row[\"success_count\"],\n",
    "        \"error_count\": row[\"error_count\"],\n",
    "        \"Abnormality_class\": abnormal_class,\n",
    "        \"time_window\": row[\"time_window\"],\n",
    "        \"ui_color\": color\n",
    "    }\n",
    "\n",
    "    # Añadir nodos\n",
    "    g.add_node(ts, src, properties=common_props, node_type=\"Microservice\")\n",
    "    g.add_node(ts, dst, properties=common_props, node_type=\"Microservice\")\n",
    "\n",
    "    # Arista con props visuales y métricas\n",
    "    edge_id = (src, dst)\n",
    "    edge_label = \"normal_link\" if abnormal_class == 1 else \"anomalous_link\"\n",
    "    edge_color = \"green\" if abnormal_class == 1 else \"red\"\n",
    "\n",
    "    if edge_id not in added_edges:\n",
    "        g.add_edge(ts, src, dst, properties={\n",
    "            \"relationship\": \"communicates\",\n",
    "            \"label\": edge_label,\n",
    "            \"ui_color\": edge_color\n",
    "        })\n",
    "        added_edges.add(edge_id)\n",
    "\n",
    "    # Añadir propiedades temporales con add_updates\n",
    "    g.edge(src, dst).add_updates(ts, properties={\n",
    "        \"average_latency\": row[\"average_latency\"],\n",
    "        \"total_request\": row[\"total_request\"],\n",
    "        \"new_request\": row[\"new_request\"],\n",
    "        \"istio_request_bytes\": row[\"istio_request_bytes\"],\n",
    "        \"Abnormality_class\": abnormal_class,\n",
    "        \"link_color\": row.get(\"link_color\", edge_color)\n",
    "    })\n",
    "\n",
    "# Guardar grafo\n",
    "g.save_to_file(output_path)\n",
    "print(\"\\u2705 Grafo completo con nodos y enlaces etiquetados y coloreados guardado en:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1d1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOTAL] checkoutservice conectó con 7 nodos.\n",
      "[ANTES de 2025-04-16 17:33:00] conectó con 7 nodos.\n",
      "[VENTANA entre 2025-04-16 17:31:00 y 2025-04-16 17:34:00] conectó con 7 nodos.\n",
      "\n",
      "Evolución de latencia entre 'frontend' y 'checkoutservice':\n",
      "2025-04-16 19:30:00: 859.2533913699232 ms\n",
      "2025-04-16 19:30:00: 859.2533913699232 ms\n",
      "2025-04-16 19:30:00: 859.2533913699232 ms\n",
      "2025-04-16 19:30:00: 859.2533913699232 ms\n",
      "2025-04-16 19:30:00: 859.2533913699232 ms\n",
      "2025-04-16 19:30:00: 859.2533913699232 ms\n",
      "2025-04-16 19:30:15: 859.2533913699232 ms\n",
      "2025-04-16 19:30:30: 859.2533913699232 ms\n",
      "2025-04-16 19:30:30: 859.2533913699232 ms\n",
      "2025-04-16 19:30:45: 859.2533913699232 ms\n",
      "2025-04-16 19:31:00: 859.2533913699232 ms\n",
      "2025-04-16 19:31:00: 859.2533913699232 ms\n",
      "2025-04-16 19:31:00: 859.2533913699232 ms\n",
      "2025-04-16 19:31:15: 859.2533913699232 ms\n",
      "2025-04-16 19:31:30: 859.2533913699232 ms\n",
      "2025-04-16 19:31:30: 859.2533913699232 ms\n",
      "2025-04-16 19:31:45: 859.2533913699232 ms\n",
      "2025-04-16 19:32:00: 859.2533913699232 ms\n",
      "2025-04-16 19:32:00: 859.2533913699232 ms\n",
      "2025-04-16 19:32:00: 859.2533913699232 ms\n",
      "2025-04-16 19:32:15: 859.2533913699232 ms\n",
      "2025-04-16 19:32:30: 859.2533913699232 ms\n",
      "2025-04-16 19:32:30: 859.2533913699232 ms\n",
      "2025-04-16 19:32:45: 859.2533913699232 ms\n",
      "2025-04-16 19:33:00: 859.2533913699232 ms\n",
      "2025-04-16 19:33:00: 859.2533913699232 ms\n",
      "2025-04-16 19:33:00: 859.2533913699232 ms\n",
      "2025-04-16 19:33:15: 859.2533913699232 ms\n",
      "2025-04-16 19:33:30: 859.2533913699232 ms\n",
      "2025-04-16 19:33:30: 859.2533913699232 ms\n",
      "2025-04-16 19:33:45: 859.2533913699232 ms\n",
      "2025-04-16 19:34:00: 859.2533913699232 ms\n",
      "2025-04-16 19:34:00: 859.2533913699232 ms\n",
      "2025-04-16 19:34:00: 859.2533913699232 ms\n",
      "2025-04-16 19:34:15: 859.2533913699232 ms\n",
      "2025-04-16 19:34:30: 859.2533913699232 ms\n",
      "2025-04-16 19:34:30: 859.2533913699232 ms\n",
      "2025-04-16 19:34:45: 859.2533913699232 ms\n",
      "2025-04-16 19:35:00: 859.2533913699232 ms\n",
      "2025-04-16 19:35:00: 859.2533913699232 ms\n",
      "2025-04-16 19:35:00: 859.2533913699232 ms\n",
      "2025-04-16 19:35:00: 859.2533913699232 ms\n",
      "2025-04-16 19:35:15: 859.2533913699232 ms\n",
      "2025-04-16 19:35:30: 859.2533913699232 ms\n",
      "2025-04-16 19:35:30: 859.2533913699232 ms\n",
      "2025-04-16 19:35:45: 859.2533913699232 ms\n",
      "2025-04-16 19:36:00: 859.2533913699232 ms\n",
      "2025-04-16 19:36:00: 859.2533913699232 ms\n",
      "2025-04-16 19:36:00: 859.2533913699232 ms\n",
      "2025-04-16 19:36:15: 859.2533913699232 ms\n",
      "2025-04-16 19:36:30: 859.2533913699232 ms\n",
      "2025-04-16 19:36:30: 859.2533913699232 ms\n",
      "2025-04-16 19:36:45: 859.2533913699232 ms\n",
      "2025-04-16 19:37:00: 859.2533913699232 ms\n",
      "2025-04-16 19:37:00: 859.2533913699232 ms\n",
      "2025-04-16 19:37:00: 859.2533913699232 ms\n",
      "2025-04-16 19:37:15: 859.2533913699232 ms\n",
      "2025-04-16 19:37:30: 859.2533913699232 ms\n",
      "2025-04-16 19:37:30: 859.2533913699232 ms\n",
      "2025-04-16 19:37:45: 859.2533913699232 ms\n",
      "2025-04-16 19:38:00: 859.2533913699232 ms\n",
      "2025-04-16 19:38:00: 859.2533913699232 ms\n",
      "2025-04-16 19:38:00: 859.2533913699232 ms\n",
      "2025-04-16 19:38:15: 859.2533913699232 ms\n",
      "2025-04-16 19:38:30: 859.2533913699232 ms\n",
      "2025-04-16 19:38:30: 859.2533913699232 ms\n",
      "2025-04-16 19:38:45: 859.2533913699232 ms\n",
      "2025-04-16 19:39:00: 859.2533913699232 ms\n",
      "2025-04-16 19:39:00: 859.2533913699232 ms\n",
      "2025-04-16 19:39:00: 859.2533913699232 ms\n",
      "2025-04-16 19:39:15: 859.2533913699232 ms\n",
      "2025-04-16 19:39:30: 859.2533913699232 ms\n",
      "2025-04-16 19:39:30: 859.2533913699232 ms\n",
      "2025-04-16 19:39:45: 859.2533913699232 ms\n",
      "2025-04-16 19:40:00: 859.2533913699232 ms\n",
      "2025-04-16 19:40:00: 859.2533913699232 ms\n",
      "2025-04-16 19:40:00: 859.2533913699232 ms\n",
      "2025-04-16 19:40:00: 859.2533913699232 ms\n",
      "2025-04-16 19:40:00: 859.2533913699232 ms\n",
      "2025-04-16 19:40:15: 859.2533913699232 ms\n",
      "2025-04-16 19:40:30: 859.2533913699232 ms\n",
      "2025-04-16 19:40:30: 859.2533913699232 ms\n",
      "2025-04-16 19:40:45: 859.2533913699232 ms\n",
      "2025-04-16 19:41:00: 859.2533913699232 ms\n",
      "2025-04-16 19:41:00: 859.2533913699232 ms\n",
      "2025-04-16 19:41:00: 859.2533913699232 ms\n",
      "2025-04-16 19:41:15: 859.2533913699232 ms\n",
      "2025-04-16 19:41:30: 859.2533913699232 ms\n",
      "2025-04-16 19:41:30: 859.2533913699232 ms\n",
      "2025-04-16 19:41:45: 859.2533913699232 ms\n",
      "2025-04-16 19:42:00: 859.2533913699232 ms\n",
      "2025-04-16 19:42:00: 859.2533913699232 ms\n",
      "2025-04-16 19:42:00: 859.2533913699232 ms\n",
      "2025-04-16 19:42:15: 859.2533913699232 ms\n",
      "2025-04-16 19:42:30: 859.2533913699232 ms\n",
      "2025-04-16 19:42:30: 859.2533913699232 ms\n",
      "2025-04-16 19:42:45: 859.2533913699232 ms\n",
      "2025-04-16 19:43:00: 859.2533913699232 ms\n",
      "2025-04-16 19:43:00: 859.2533913699232 ms\n",
      "2025-04-16 19:43:00: 859.2533913699232 ms\n",
      "2025-04-16 19:43:15: 859.2533913699232 ms\n",
      "2025-04-16 19:43:30: 859.2533913699232 ms\n",
      "2025-04-16 19:43:30: 859.2533913699232 ms\n",
      "2025-04-16 19:43:45: 859.2533913699232 ms\n",
      "2025-04-16 19:44:00: 859.2533913699232 ms\n",
      "2025-04-16 19:44:00: 859.2533913699232 ms\n",
      "2025-04-16 19:44:00: 859.2533913699232 ms\n",
      "2025-04-16 19:44:15: 859.2533913699232 ms\n",
      "2025-04-16 19:44:30: 859.2533913699232 ms\n",
      "2025-04-16 19:44:30: 859.2533913699232 ms\n",
      "2025-04-16 19:44:45: 859.2533913699232 ms\n",
      "2025-04-16 19:45:00: 859.2533913699232 ms\n",
      "2025-04-16 19:45:00: 859.2533913699232 ms\n",
      "2025-04-16 19:45:00: 859.2533913699232 ms\n",
      "2025-04-16 19:45:00: 859.2533913699232 ms\n",
      "2025-04-16 19:45:15: 859.2533913699232 ms\n",
      "2025-04-16 19:45:30: 859.2533913699232 ms\n",
      "2025-04-16 19:45:30: 859.2533913699232 ms\n",
      "2025-04-16 19:45:45: 859.2533913699232 ms\n",
      "2025-04-16 19:46:00: 859.2533913699232 ms\n",
      "2025-04-16 19:46:00: 859.2533913699232 ms\n",
      "2025-04-16 19:46:00: 859.2533913699232 ms\n",
      "2025-04-16 19:46:15: 859.2533913699232 ms\n",
      "2025-04-16 19:46:30: 859.2533913699232 ms\n",
      "2025-04-16 19:46:30: 859.2533913699232 ms\n",
      "2025-04-16 19:46:45: 859.2533913699232 ms\n",
      "2025-04-16 19:47:00: 859.2533913699232 ms\n",
      "2025-04-16 19:47:00: 859.2533913699232 ms\n",
      "2025-04-16 19:47:00: 859.2533913699232 ms\n",
      "2025-04-16 19:47:15: 859.2533913699232 ms\n",
      "2025-04-16 19:47:30: 859.2533913699232 ms\n",
      "2025-04-16 19:47:30: 859.2533913699232 ms\n",
      "2025-04-16 19:47:45: 859.2533913699232 ms\n",
      "2025-04-16 19:48:00: 859.2533913699232 ms\n",
      "2025-04-16 19:48:00: 859.2533913699232 ms\n",
      "2025-04-16 19:48:00: 859.2533913699232 ms\n",
      "2025-04-16 19:48:15: 859.2533913699232 ms\n",
      "2025-04-16 19:48:30: 859.2533913699232 ms\n",
      "2025-04-16 19:48:30: 859.2533913699232 ms\n",
      "2025-04-16 19:48:45: 859.2533913699232 ms\n",
      "2025-04-16 19:49:00: 859.2533913699232 ms\n",
      "2025-04-16 19:49:00: 859.2533913699232 ms\n",
      "2025-04-16 19:49:00: 859.2533913699232 ms\n",
      "2025-04-16 19:49:15: 859.2533913699232 ms\n",
      "2025-04-16 19:49:30: 859.2533913699232 ms\n",
      "2025-04-16 19:49:30: 859.2533913699232 ms\n",
      "2025-04-16 19:49:45: 859.2533913699232 ms\n",
      "2025-04-16 19:50:00: 859.2533913699232 ms\n",
      "2025-04-16 19:50:00: 859.2533913699232 ms\n",
      "2025-04-16 19:50:00: 859.2533913699232 ms\n",
      "2025-04-16 19:50:00: 859.2533913699232 ms\n",
      "2025-04-16 19:50:00: 859.2533913699232 ms\n"
     ]
    }
   ],
   "source": [
    "from raphtory import Graph\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar el grafo desde archivo\n",
    "g = Graph.load_from_file(\"graphs/microservices_graph_enriched_temporal\")\n",
    "\n",
    "# Nodo a consultar\n",
    "node_name = \"checkoutservice\"\n",
    "node = g.node(node_name)\n",
    "\n",
    "print(f\"[TOTAL] {node_name} conectó con {node.degree()} nodos.\")\n",
    "\n",
    "# Consulta temporal: antes de cierto instante\n",
    "cutoff = datetime.strptime(\"2025-04-16 17:33:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "node_before = g.before(cutoff).node(node_name)\n",
    "print(f\"[ANTES de {cutoff}] conectó con {node_before.degree()} nodos.\")\n",
    "\n",
    "# Consulta temporal: entre dos tiempos específicos\n",
    "start = datetime.strptime(\"2025-04-16 17:31:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "end = datetime.strptime(\"2025-04-16 17:34:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "node_window = g.node(node_name).window(start, end)\n",
    "print(f\"[VENTANA entre {start} y {end}] conectó con {node_window.degree()} nodos.\")\n",
    "\n",
    "# Evolución temporal de latencia entre frontend y checkoutservice\n",
    "graph_edge = g.edge(\"frontend\", \"checkoutservice\")\n",
    "print(\"\\nEvolución de latencia entre 'frontend' y 'checkoutservice':\")\n",
    "\n",
    "for update in graph_edge.history():\n",
    "    time = datetime.fromtimestamp(update / 1000)  # Convert milliseconds to seconds and then to datetime\n",
    "    latency = graph_edge.properties[\"average_latency\"] if \"average_latency\" in graph_edge.properties else \"N/A\"\n",
    "    print(f\"{time}: {latency} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7759beb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: raphtory[visualisation] in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[visualisation]) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=18 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[visualisation]) (19.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[visualisation]) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=2.0.3->raphtory[visualisation]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=2.0.3->raphtory[visualisation]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=2.0.3->raphtory[visualisation]) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->raphtory[visualisation]) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: raphtory 0.15.1 does not provide the extra 'visualisation'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install raphtory[visualisation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4f152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: raphtory[all] in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=18 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (19.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=2.0.3->raphtory[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=2.0.3->raphtory[all]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=2.0.3->raphtory[all]) (2025.2)\n",
      "Requirement already satisfied: seaborn>=0.11.2 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (0.13.2)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.4.3->raphtory[all]) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->raphtory[all]) (1.17.0)\n",
      "Requirement already satisfied: networkx>=2.6.3 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (3.4.2)\n",
      "Requirement already satisfied: pyvis>=0.3.2 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from raphtory[all]) (0.3.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from pyvis>=0.3.2->raphtory[all]) (8.35.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyvis>=0.3.2->raphtory[all]) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyvis>=0.3.2->raphtory[all]) (4.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (4.4.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (4.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marti\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2>=2.9.6->pyvis>=0.3.2->raphtory[all]) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->raphtory[all]) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"raphtory[all]\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60672dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿DataFrame vacío?: False\n",
      "Columnas: ['source_workload', 'destination_workload', 'timestamp', 'total_request', 'new_request', 'success_count', 'error_count', 'success_rate', 'error_rate', 'average_latency', 'istio_request_bytes', 'throughput', 'request_rate', 'time_window', 'link_color', 'Abnormality class']\n",
      "Primeras filas:\n",
      "   source_workload destination_workload            timestamp  total_request  \\\n",
      "0  checkoutservice          cartservice  2025-04-16 17:30:00         9385.0   \n",
      "1  checkoutservice          cartservice  2025-04-16 17:30:15         9447.0   \n",
      "2  checkoutservice          cartservice  2025-04-16 17:30:30         9491.0   \n",
      "3  checkoutservice          cartservice  2025-04-16 17:30:45         9555.0   \n",
      "4  checkoutservice          cartservice  2025-04-16 17:31:00         9625.0   \n",
      "\n",
      "   new_request  success_count  error_count  success_rate  error_rate  \\\n",
      "0          0.0            0.0          0.0           NaN         NaN   \n",
      "1         62.0           62.0          0.0           1.0         0.0   \n",
      "2         44.0           44.0          0.0           1.0         0.0   \n",
      "3         64.0           64.0          0.0           1.0         0.0   \n",
      "4         70.0           70.0          0.0           1.0         0.0   \n",
      "\n",
      "   average_latency  istio_request_bytes  throughput  request_rate time_window  \\\n",
      "0         0.000000                  0.0    0.000000      0.000000         15S   \n",
      "1        10.983065              12750.0  850.000000      4.133333         15S   \n",
      "2         0.810227               6875.0  458.333333      2.933333         15S   \n",
      "3         0.782031              12875.0  858.333333      4.266667         15S   \n",
      "4         0.672143              13125.0  875.000000      4.666667         15S   \n",
      "\n",
      "  link_color Abnormality class  \n",
      "0      green            Normal  \n",
      "1      green            Normal  \n",
      "2      green            Normal  \n",
      "3      green            Normal  \n",
      "4      green            Normal  \n",
      "Valores únicos en 'Abnormality class': ['Normal' 'Anomalous']\n",
      "✅ Grafo generado correctamente. Abre 'grafo_microservicios.html'\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV\n",
    "df = pd.read_csv('./results/kiali_kpi_metrics_processed.csv')\n",
    "# Diagnóstico rápido del DataFrame\n",
    "print(\"¿DataFrame vacío?:\", df.empty)\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "print(\"Primeras filas:\")\n",
    "print(df.head())\n",
    "print(\"Valores únicos en 'Abnormality class':\", df[\"Abnormality class\"].unique())\n",
    "\n",
    "# Crear red visual\n",
    "net = Network(height=\"750px\", width=\"100%\", directed=True, notebook=False, cdn_resources=\"in_line\")\n",
    "net.barnes_hut()  # Mejora la dispersión\n",
    "\n",
    "# Usar sets para evitar duplicados\n",
    "added_nodes = set()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    src = row[\"source_workload\"]\n",
    "    dst = row[\"destination_workload\"]\n",
    "    # Convert 'Abnormality class' to an integer or map string values to integers\n",
    "    abnormal_mapping = {\"Normal\": 1, \"Anomalous\": 2}  # Example mapping\n",
    "    abnormal = abnormal_mapping.get(row[\"Abnormality class\"], 0)  # Default to 0 if not found\n",
    "    color = \"green\" if abnormal == 1 else \"red\"\n",
    "\n",
    "    # Añadir nodos solo si no han sido agregados\n",
    "    if src not in added_nodes:\n",
    "        net.add_node(src, label=src, color=color, shape=\"dot\", title=f\"Abnormality class: {abnormal}\")\n",
    "        added_nodes.add(src)\n",
    "    if dst not in added_nodes:\n",
    "        net.add_node(dst, label=dst, color=color, shape=\"dot\", title=f\"Abnormality class: {abnormal}\")\n",
    "        added_nodes.add(dst)\n",
    "\n",
    "    # Añadir arista con información\n",
    "    net.add_edge(\n",
    "        src, dst,\n",
    "        label=\"⚠️\" if abnormal > 1 else \"✔️\",\n",
    "        title=f\"Latency: {row['average_latency']}, Requests: {row['total_request']}\",\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# Exportar grafo con encoding explícito\n",
    "with open(\"grafo_microservicios.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())\n",
    "\n",
    "\n",
    "#para un unico enlace por relación\n",
    "# # Calcular porcentaje de peticiones normales por cada par (src, dst)\n",
    "# grouped = df.groupby(['source_workload', 'destination_workload'])['Abnormality class']\n",
    "# percent_normal = grouped.apply(lambda x: (x == 'Normal').mean() * 100).to_dict()\n",
    "\n",
    "# # Usar sets para evitar duplicados\n",
    "# added_nodes = set()\n",
    "# added_edges = set()  # Añade esto antes del bucle\n",
    "\n",
    "\n",
    "# for _, row in df.iterrows():\n",
    "#     src = row[\"source_workload\"]\n",
    "#     dst = row[\"destination_workload\"]\n",
    "#     # Convert 'Abnormality class' to an integer or map string values to integers\n",
    "#     abnormal_mapping = {\"Normal\": 1, \"Anomalous\": 2}  # Example mapping\n",
    "#     abnormal = abnormal_mapping.get(row[\"Abnormality class\"], 0)  # Default to 0 if not found\n",
    "#     color = \"green\" if abnormal == 1 else \"red\"\n",
    "\n",
    "#     # Añadir nodos solo si no han sido agregados\n",
    "#     if src not in added_nodes:\n",
    "#         net.add_node(src, label=src, color=color, shape=\"dot\", title=f\"Abnormality class: {abnormal}\")\n",
    "#         added_nodes.add(src)\n",
    "#     if dst not in added_nodes:\n",
    "#         net.add_node(dst, label=dst, color=color, shape=\"dot\", title=f\"Abnormality class: {abnormal}\")\n",
    "#         added_nodes.add(dst)\n",
    "\n",
    "#     # Añadir arista con información\n",
    "#     edge_id = (src, dst)\n",
    "#     if edge_id not in added_edges:\n",
    "#         pct = percent_normal.get(edge_id, 0)\n",
    "#         color = \"green\" if pct >= 95 else \"red\"\n",
    "#         label = f\"{pct:.1f}% Normal\"\n",
    "#         net.add_edge(\n",
    "#             src, dst,\n",
    "#             label=label,\n",
    "#             title=f\"Porcentaje de normales: {pct:.1f}%\",\n",
    "#             color=color\n",
    "#         )\n",
    "#         added_edges.add(edge_id)\n",
    "\n",
    "\n",
    "\n",
    "print(\"✅ Grafo generado correctamente. Abre 'grafo_microservicios.html'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a1c91",
   "metadata": {},
   "source": [
    "# Abre una terminal en la carpeta del archivo\n",
    "cd /ruta/del/archivo\n",
    "python -m http.server 8000\n",
    "http://localhost:8000/grafo_microservicios.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101aee0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grafo_anomalous_only.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "# Crear red visual solo con nodos y enlaces anómalos\n",
    "net = Network(height=\"750px\", width=\"100%\", directed=True, notebook=False, cdn_resources=\"in_line\")\n",
    "net.barnes_hut()\n",
    "anomalous_df = pd.read_csv('./Nodos_An_malos.csv')\n",
    "\n",
    "# Añadir nodos y aristas únicos\n",
    "added_nodes = set()\n",
    "for _, row in anomalous_df.iterrows():\n",
    "    src = row[\"source_workload\"]\n",
    "    dst = row[\"destination_workload\"]\n",
    "    color = \"red\"\n",
    "    label = \"anomalous\"\n",
    "\n",
    "    if src not in added_nodes:\n",
    "        net.add_node(src, label=src, color=color, shape=\"dot\", title=\"Anomalous Node\")\n",
    "        added_nodes.add(src)\n",
    "    if dst not in added_nodes:\n",
    "        net.add_node(dst, label=dst, color=color, shape=\"dot\", title=\"Anomalous Node\")\n",
    "        added_nodes.add(dst)\n",
    "\n",
    "    net.add_edge(\n",
    "        src, dst,\n",
    "        label=label,\n",
    "        title=f\"Latency: {row['average_latency']}, Error rate: {row['error_rate']}\",\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# Guardar como archivo HTML\n",
    "output_path = \"grafo_anomalous_only.html\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())\n",
    "\n",
    "output_path\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
