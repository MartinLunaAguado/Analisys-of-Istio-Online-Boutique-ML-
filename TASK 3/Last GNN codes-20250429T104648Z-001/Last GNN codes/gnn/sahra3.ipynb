{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\2343514634.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['grpc_response_status'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "file_path = \"istio_request_v3.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['grpc_response_status'].fillna(0, inplace=True)\n",
    "\n",
    "df['response_flags'] = df['response_flags'].astype(str).str.strip()  # Convertir en string et enlever espaces\n",
    "\n",
    "# Ajouter une colonne 'result' avec 'success' ou 'error'\n",
    "df['result'] = df.apply(\n",
    "    lambda row: 'success' if row['response_code'] == 200 and row['grpc_response_status'] == 0 and row['response_flags'] == '-' else 'error',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Réorganiser les données par 'source_workload', 'destination_workload' et 'timestamp'\n",
    "df_sorted = df.sort_values(by=['source_workload', 'destination_workload', 'timestamp'])\n",
    "\n",
    "# Sauvegarder le fichier résultant\n",
    "df_sorted.to_csv(\"aggregated_istio_data.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_success['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\195866431.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement terminé. Fichier sauvegardé sous 'new_request_istio_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"aggregated_istio_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir timestamp en datetime pour le tri\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Trier avant la séparation\n",
    "df.sort_values(by=['source_workload', 'destination_workload', 'timestamp'], inplace=True)\n",
    "\n",
    "# Séparer les succès\n",
    "df_success = df[df['result'] == 'success'].copy()\n",
    "\n",
    "# Calculer new_request, new_istio_request_bytes et new_istio_request_duration_milliseconds avec 0 pour la première ligne\n",
    "df_success['new_request'] = df_success.groupby(['source_workload', 'destination_workload'])['total_request'].diff().fillna(0)\n",
    "df_success['new_istio_request_bytes'] = df_success.groupby(['source_workload', 'destination_workload'])['istio_request_bytes_sum'].diff().fillna(0)\n",
    "df_success['new_istio_request_duration_milliseconds'] = df_success.groupby(['source_workload', 'destination_workload'])['istio_request_duration_milliseconds_sum'].diff().fillna(0)\n",
    "\n",
    "# Appliquer la condition si new_request == 0\n",
    "df_success.loc[df_success['new_request'] == 0, ['new_istio_request_bytes', 'new_istio_request_duration_milliseconds']] = 0\n",
    "\n",
    "# Calculer latency\n",
    "df_success['latency'] = df_success['new_istio_request_duration_milliseconds'] / df_success['new_request']\n",
    "df_success['latency'].fillna(0, inplace=True)\n",
    "\n",
    "# Sauvegarder les succès dans un fichier\n",
    "df_success.to_csv(\"success_istio_data.csv\", index=False)\n",
    "\n",
    "# Séparer les erreurs HTTP et gRPC\n",
    "df_http_errors = df[(df['result'] == 'error') & (df['request_protocol'] == 'http')].copy()\n",
    "df_grpc_errors = df[(df['result'] == 'error') & (df['request_protocol'] == 'grpc')].copy()\n",
    "\n",
    "error_files = []  # Liste des fichiers d'erreur générés\n",
    "\n",
    "# Traitement des erreurs HTTP\n",
    "http_groups = df_http_errors.groupby(['request_protocol', 'response_code', 'grpc_response_status', 'response_flags'])\n",
    "\n",
    "for (request_protocol, response_code, grpc_status, response_flags), df_error in http_groups:\n",
    "    df_error = df_error.copy()\n",
    "    \n",
    "    # Calculer new_request, new_istio_request_bytes et new_istio_request_duration_milliseconds avec 0 pour la première ligne\n",
    "    df_error['new_request'] = df_error.groupby(['source_workload', 'destination_workload'])['total_request'].diff().fillna(0)\n",
    "    df_error['new_istio_request_bytes'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_bytes_sum'].diff().fillna(0)\n",
    "    df_error['new_istio_request_duration_milliseconds'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_duration_milliseconds_sum'].diff().fillna(0)\n",
    "    \n",
    "    # Appliquer la condition si new_request == 0\n",
    "    df_error.loc[df_error['new_request'] == 0, ['new_istio_request_bytes', 'new_istio_request_duration_milliseconds']] = 0\n",
    "    \n",
    "    # Calculer latency\n",
    "    df_error['latency'] = df_error['new_istio_request_duration_milliseconds'] / df_error['new_request']\n",
    "    df_error['latency'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Nommer le fichier selon l'erreur\n",
    "    file_name = f\"error_{request_protocol}_{response_code}_{response_flags}.csv\"\n",
    "    df_error.to_csv(file_name, index=False)\n",
    "    error_files.append(df_error)\n",
    "\n",
    "# Traitement des erreurs gRPC\n",
    "grpc_groups = df_grpc_errors.groupby(['request_protocol', 'response_code', 'grpc_response_status', 'response_flags'])\n",
    "\n",
    "for (request_protocol, response_code, grpc_status, response_flags), df_error in grpc_groups:\n",
    "    df_error = df_error.copy()\n",
    "    \n",
    "    # Calculer new_request, new_istio_request_bytes et new_istio_request_duration_milliseconds avec 0 pour la première ligne\n",
    "    df_error['new_request'] = df_error.groupby(['source_workload', 'destination_workload'])['total_request'].diff().fillna(0)\n",
    "    df_error['new_istio_request_bytes'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_bytes_sum'].diff().fillna(0)\n",
    "    df_error['new_istio_request_duration_milliseconds'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_duration_milliseconds_sum'].diff().fillna(0)\n",
    "    \n",
    "    # Appliquer la condition si new_request == 0\n",
    "    df_error.loc[df_error['new_request'] == 0, ['new_istio_request_bytes', 'new_istio_request_duration_milliseconds']] = 0\n",
    "    \n",
    "    # Calculer latency\n",
    "    df_error['latency'] = df_error['new_istio_request_duration_milliseconds'] / df_error['new_request']\n",
    "    df_error['latency'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Nommer le fichier selon l'erreur\n",
    "    file_name = f\"error_{request_protocol}_{response_code}_{grpc_status}_{response_flags}.csv\"\n",
    "    df_error.to_csv(file_name, index=False)\n",
    "    error_files.append(df_error)\n",
    "\n",
    "# Fusionner tous les fichiers (success + errors)\n",
    "df_final = pd.concat([df_success] + error_files).sort_values(by=['source_workload', 'destination_workload', 'timestamp'])\n",
    "\n",
    "# Sauvegarder le fichier final\n",
    "df_final.to_csv(\"new_request_istio_data.csv\", index=False)\n",
    "\n",
    "print(\"Traitement terminé. Fichier sauvegardé sous 'new_request_istio_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement terminé. Fichier sauvegardé sous aggregated_istio_rates.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"new_request_istio_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Trier les données\n",
    "df.sort_values(by=['source_workload', 'destination_workload', 'timestamp'], inplace=True)\n",
    "\n",
    "# Calculer success rate, error rate, success count, error count, duration success request, duration error request et average latency par timestamp\n",
    "grouped = df.groupby(['source_workload', 'destination_workload', 'timestamp'])\n",
    "aggregated_rows = []\n",
    "\n",
    "for (src, dst, ts), group in grouped:\n",
    "    total_new_request = group['new_request'].sum()\n",
    "    success_count = group[group['result'] == 'success']['new_request'].sum()\n",
    "    error_count = total_new_request - success_count\n",
    "    \n",
    "    if total_new_request > 0:\n",
    "        success_rate = success_count / total_new_request\n",
    "        error_rate = 1 - success_rate\n",
    "    else:\n",
    "        success_rate = float('nan')\n",
    "        error_rate = float('nan')\n",
    "    \n",
    "    # Calculer la durée des requêtes réussies et erronées\n",
    "    duration_success_request = group[group['result'] == 'success']['latency'].sum()\n",
    "    duration_error_request = group[group['result'] == 'error']['latency'].sum()\n",
    "    average_latency = duration_success_request + duration_error_request\n",
    "\n",
    "    # Séparer new_istio_request_bytes en success et error\n",
    "    new_istio_request_bytes_success = group[group['result'] == 'success']['new_istio_request_bytes'].sum()\n",
    "    new_istio_request_bytes_error = group[group['result'] == 'error']['new_istio_request_bytes'].sum()\n",
    "    istio_request_bytes = new_istio_request_bytes_success+new_istio_request_bytes_error\n",
    "    istio_request_duration_milliseconds = group['new_istio_request_duration_milliseconds'].sum()\n",
    "\n",
    "    aggregated_rows.append([ts, src, dst, group['total_request'].max(), total_new_request, success_count, error_count, success_rate, error_rate, duration_success_request, duration_error_request, average_latency, new_istio_request_bytes_success, new_istio_request_bytes_error,istio_request_bytes,istio_request_duration_milliseconds])\n",
    "\n",
    "# Créer un DataFrame final\n",
    "df_final = pd.DataFrame(aggregated_rows, columns=['timestamp', 'source_workload', 'destination_workload', 'total_request', 'new_request', 'success_count', 'error_count', 'success_rate', 'error_rate', 'duration_success_request', 'duration_error_request', 'average_latency', 'new_istio_request_bytes_success', 'new_istio_request_bytes_error','istio_request_bytes','duration_milliseconds'])\n",
    "\n",
    "# Sauvegarder le fichier\n",
    "output_file = \"aggregated_istio_rates.csv\"\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Traitement terminé. Fichier sauvegardé sous {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:23: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  .resample(window, on='timestamp', label='right', closed='right')\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:23: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  .resample(window, on='timestamp', label='right', closed='right')\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_25648\\3400376227.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"aggregated_istio_rates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Définir les fenêtres de temps\n",
    "time_windows = ['15S', '30S', '1min', '5min', '10min']\n",
    "\n",
    "# Initialiser un tableau pour stocker les résultats\n",
    "kpi_results = []\n",
    "\n",
    "for window in time_windows:\n",
    "    # Resample par fenêtre de temps\n",
    "    df_resampled = (\n",
    "        df\n",
    "        .groupby(['source_workload', 'destination_workload'])\n",
    "        .resample(window, on='timestamp', label='right', closed='right')\n",
    "        .agg({\n",
    "            'total_request': 'max',\n",
    "            'new_request': 'sum',\n",
    "            'success_count': 'sum',\n",
    "            'error_count': 'sum',\n",
    "            'success_rate': 'mean',\n",
    "            'error_rate': 'mean',\n",
    "            'average_latency': 'sum',\n",
    "            'istio_request_bytes': 'sum',\n",
    "            'duration_milliseconds': 'sum'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Pour chaque pair source-destination, calculer la vraie durée entre deux points non nuls\n",
    "    def compute_real_durations(group):\n",
    "        # Garder le timestamp courant pour référence\n",
    "        last_time = None\n",
    "        last_index = None\n",
    "        durations = []\n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            if row['new_request'] > 0:\n",
    "                if last_time is not None:\n",
    "                    duration = (row['timestamp'] - last_time).total_seconds()\n",
    "                    durations.append(duration)\n",
    "                else:\n",
    "                    durations.append(np.nan)\n",
    "                last_time = row['timestamp']\n",
    "                last_index = idx\n",
    "            else:\n",
    "                durations.append(np.nan)\n",
    "        # Remplir les valeurs manquantes en regardant en avant\n",
    "        return pd.Series(durations, index=group.index)\n",
    "\n",
    "    # Appliquer la fonction à chaque groupe\n",
    "    df_resampled['real_duration'] = (\n",
    "        df_resampled\n",
    "        .groupby(['source_workload', 'destination_workload'])\n",
    "        .apply(compute_real_durations)\n",
    "        .reset_index(level=[0,1], drop=True)\n",
    "    )\n",
    "\n",
    "    # Calcul des KPI\n",
    "    df_resampled['throughput'] = df_resampled['istio_request_bytes'] / df_resampled['real_duration']\n",
    "    df_resampled['request_rate'] = df_resampled['new_request'] / df_resampled['real_duration']\n",
    "\n",
    "    # Ajouter la fenêtre utilisée\n",
    "    df_resampled['time_window'] = window\n",
    "\n",
    "    kpi_results.append(df_resampled)\n",
    "\n",
    "# Concaténer tous les résultats\n",
    "df_final = pd.concat(kpi_results)\n",
    "\n",
    "# Supprimer la ligne où timestamp == \"2025-04-02 15:21:00\"\n",
    "starting_point = pd.Timestamp(\"2025-04-08 00:15:00\")\n",
    "df_final = df_final[df_final['timestamp'] != starting_point]\n",
    "\n",
    "# Sauvegarder dans un fichier CSV\n",
    "df_final.to_csv(\"kiali_kpi_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating percentiles for row 389 in window 15S: repeats may not contain negative values.\n",
      "Error calculating percentiles for row 208 in window 30S: repeats may not contain negative values.\n",
      "Error calculating percentiles for row 97 in window 1min: repeats may not contain negative values.\n",
      "Error calculating percentiles for row 41 in window 5min: repeats may not contain negative values.\n",
      "Error calculating percentiles for row 55 in window 10min: negative dimensions are not allowed\n",
      "Traitement terminé. Fichier sauvegardé sous kiali_latency_percentiles.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier\n",
    "df = pd.read_csv(\"kiali_kpi_metrics.csv\")\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Définir les fenêtres de temps et leurs intervalles respectifs\n",
    "interval_mapping = {\n",
    "    '15S': '1min',  # 15 secondes -> 1 minute\n",
    "    '30S': '2min',  # 30 secondes -> 2 minutes\n",
    "    '1min': '4min',  # 1 minute -> 4 minutes\n",
    "    '5min': '10min',  # 5 minutes -> 10 minutes\n",
    "    '10min': '10min'  # 10 minutes -> 10 minutes\n",
    "}\n",
    "\n",
    "latency_results = []\n",
    "\n",
    "for window, interval in interval_mapping.items():\n",
    "    df_filtered = df[df['time_window'] == window].copy()\n",
    "    if df_filtered.empty:\n",
    "        print(f\"No data for time window: {window}\")\n",
    "        continue\n",
    "    \n",
    "    df_filtered.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    try:\n",
    "        df_grouped = (df_filtered.groupby(['source_workload', 'destination_workload'])\n",
    "                      .resample(interval)\n",
    "                      .agg({col: list for col in df.columns if col not in ['timestamp', 'source_workload', 'destination_workload', 'time_window']})\n",
    "                      .reset_index())\n",
    "    except Exception as e:\n",
    "        print(f\"Error during resampling for window {window}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    for idx, row in df_grouped.iterrows():\n",
    "        values = row.get('average_latency', [])\n",
    "        frequencies = row.get('new_request', [])\n",
    "        \n",
    "        if not values or not frequencies or len(values) != len(frequencies):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            data = np.repeat(values, frequencies)\n",
    "            if data.size == 0:\n",
    "                continue\n",
    "            \n",
    "            percentiles = {\n",
    "                'p50_latency': np.percentile(data, 50),\n",
    "                'p90_latency': np.percentile(data, 90),\n",
    "                'p95_latency': np.percentile(data, 95),\n",
    "                'p99_latency': np.percentile(data, 99)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating percentiles for row {idx} in window {window}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        result = {**row.to_dict(), **percentiles, 'time_window': window}\n",
    "        latency_results.append(result)\n",
    "\n",
    "# Créer un DataFrame final\n",
    "df_latency = pd.DataFrame(latency_results)\n",
    "\n",
    "# Sauvegarder dans un fichier CSV\n",
    "df_latency.to_csv(\"kiali_latency_percentiles.csv\", index=False)\n",
    "\n",
    "print(\"Traitement terminé. Fichier sauvegardé sous kiali_latency_percentiles.csv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
