{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce176ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0           timestamp  \\\n",
      "0           0 2025-04-21 20:41:30   \n",
      "1           1 2025-04-21 20:41:31   \n",
      "2           2 2025-04-21 20:41:32   \n",
      "3           3 2025-04-21 20:41:33   \n",
      "4           4 2025-04-21 20:41:34   \n",
      "\n",
      "   adservice-5dc4c759b6-w5p8z_container_cpu_usage_seconds_total  \\\n",
      "0                                           0.014576              \n",
      "1                                           0.014576              \n",
      "2                                           0.014576              \n",
      "3                                           0.014576              \n",
      "4                                           0.014576              \n",
      "\n",
      "   adservice-5dc4c759b6-w5p8z_container_memory_working_set_bytes  \\\n",
      "0                                       1.350542e+06               \n",
      "1                                       1.350542e+06               \n",
      "2                                       1.350542e+06               \n",
      "3                                       1.350542e+06               \n",
      "4                                       1.350542e+06               \n",
      "\n",
      "   adservice-5dc4c759b6-w5p8z_container_network_transmit_packets_total  \\\n",
      "0                                           4.341871                     \n",
      "1                                           4.341871                     \n",
      "2                                           4.341871                     \n",
      "3                                           4.341871                     \n",
      "4                                           4.341871                     \n",
      "\n",
      "  adservice-5dc4c759b6-w5p8z_deployed_at  \\\n",
      "0      aks-agentpool-42554999-vmss000011   \n",
      "1      aks-agentpool-42554999-vmss000011   \n",
      "2      aks-agentpool-42554999-vmss000011   \n",
      "3      aks-agentpool-42554999-vmss000011   \n",
      "4      aks-agentpool-42554999-vmss000011   \n",
      "\n",
      "   cartservice-7f84c9f647-bltfq_container_cpu_usage_seconds_total  \\\n",
      "0                                           0.008088                \n",
      "1                                           0.008088                \n",
      "2                                           0.008088                \n",
      "3                                           0.008088                \n",
      "4                                           0.008246                \n",
      "\n",
      "   cartservice-7f84c9f647-bltfq_container_memory_working_set_bytes  \\\n",
      "0                                       1.749457e+06                 \n",
      "1                                       1.749457e+06                 \n",
      "2                                       1.749457e+06                 \n",
      "3                                       1.749457e+06                 \n",
      "4                                       1.240170e+06                 \n",
      "\n",
      "   cartservice-7f84c9f647-bltfq_container_network_transmit_packets_total  \\\n",
      "0                                           9.461806                       \n",
      "1                                           9.461806                       \n",
      "2                                           9.461806                       \n",
      "3                                           9.461806                       \n",
      "4                                           9.461806                       \n",
      "\n",
      "  cartservice-7f84c9f647-bltfq_deployed_at  ...  \\\n",
      "0        aks-agentpool-42554999-vmss00000y  ...   \n",
      "1        aks-agentpool-42554999-vmss00000y  ...   \n",
      "2        aks-agentpool-42554999-vmss00000y  ...   \n",
      "3        aks-agentpool-42554999-vmss00000y  ...   \n",
      "4        aks-agentpool-42554999-vmss00000y  ...   \n",
      "\n",
      "   loadgenerator-7785849b66-vhwdf_container_network_transmit_packets_total  \\\n",
      "0                                                NaN                         \n",
      "1                                                NaN                         \n",
      "2                                                NaN                         \n",
      "3                                                NaN                         \n",
      "4                                                NaN                         \n",
      "\n",
      "   loadgenerator-7785849b66-vhwdf_deployed_at  \\\n",
      "0                                         NaN   \n",
      "1                                         NaN   \n",
      "2                                         NaN   \n",
      "3                                         NaN   \n",
      "4                                         NaN   \n",
      "\n",
      "   loadgenerator-64fb74c986-62785_container_cpu_usage_seconds_total  \\\n",
      "0                                                NaN                  \n",
      "1                                                NaN                  \n",
      "2                                                NaN                  \n",
      "3                                                NaN                  \n",
      "4                                                NaN                  \n",
      "\n",
      "  loadgenerator-64fb74c986-62785_container_memory_working_set_bytes  \\\n",
      "0                                                NaN                  \n",
      "1                                                NaN                  \n",
      "2                                                NaN                  \n",
      "3                                                NaN                  \n",
      "4                                                NaN                  \n",
      "\n",
      "   loadgenerator-64fb74c986-62785_container_network_transmit_packets_total  \\\n",
      "0                                                NaN                         \n",
      "1                                                NaN                         \n",
      "2                                                NaN                         \n",
      "3                                                NaN                         \n",
      "4                                                NaN                         \n",
      "\n",
      "   loadgenerator-64fb74c986-62785_deployed_at  \\\n",
      "0                                         NaN   \n",
      "1                                         NaN   \n",
      "2                                         NaN   \n",
      "3                                         NaN   \n",
      "4                                         NaN   \n",
      "\n",
      "   loadgenerator-64fb74c986-9fjcn_container_cpu_usage_seconds_total  \\\n",
      "0                                                NaN                  \n",
      "1                                                NaN                  \n",
      "2                                                NaN                  \n",
      "3                                                NaN                  \n",
      "4                                                NaN                  \n",
      "\n",
      "  loadgenerator-64fb74c986-9fjcn_container_memory_working_set_bytes  \\\n",
      "0                                                NaN                  \n",
      "1                                                NaN                  \n",
      "2                                                NaN                  \n",
      "3                                                NaN                  \n",
      "4                                                NaN                  \n",
      "\n",
      "   loadgenerator-64fb74c986-9fjcn_container_network_transmit_packets_total  \\\n",
      "0                                                NaN                         \n",
      "1                                                NaN                         \n",
      "2                                                NaN                         \n",
      "3                                                NaN                         \n",
      "4                                                NaN                         \n",
      "\n",
      "   loadgenerator-64fb74c986-9fjcn_deployed_at  \n",
      "0                                         NaN  \n",
      "1                                         NaN  \n",
      "2                                         NaN  \n",
      "3                                         NaN  \n",
      "4                                         NaN  \n",
      "\n",
      "[5 rows x 265 columns]\n",
      "             timestamp        source_workload   destination_workload  \\\n",
      "0  2025-04-21 20:41:30               frontend              adservice   \n",
      "1  2025-04-21 20:41:30        checkoutservice        currencyservice   \n",
      "2  2025-04-21 20:41:30  recommendationservice  productcatalogservice   \n",
      "3  2025-04-21 20:41:30               frontend        checkoutservice   \n",
      "4  2025-04-21 20:41:30               frontend  recommendationservice   \n",
      "\n",
      "  request_protocol response_flags     reporter  response_code  \\\n",
      "0             grpc              -  destination            200   \n",
      "1             grpc              -  destination            200   \n",
      "2             grpc              -  destination            200   \n",
      "3             grpc              -  destination            200   \n",
      "4             grpc              -  destination            200   \n",
      "\n",
      "   grpc_response_status  total_request  istio_request_bytes_sum  \\\n",
      "0                   0.0          122.0                  21838.5   \n",
      "1                   0.0            7.0                   2430.0   \n",
      "2                   0.0          162.0                  29143.0   \n",
      "3                   0.0            3.0                   2340.0   \n",
      "4                   0.0          165.0                  37940.0   \n",
      "\n",
      "   istio_request_duration_milliseconds_sum   Microservice Experiment  \n",
      "0                                   457.50  adservice_cpu          1  \n",
      "1                                     3.15  adservice_cpu          1  \n",
      "2                                     0.00  adservice_cpu          1  \n",
      "3                                   155.00  adservice_cpu          1  \n",
      "4                                   383.55  adservice_cpu          1  \n",
      "‚úÖ Fichiers 'final_pod_resource_baro_dataset.csv' et 'final_pod_communication_dataset.csv' enregistr√©s avec succ√®s !\n",
      "üìå Distribution des classes :\n",
      " Abnormality class\n",
      "Normal          3420\n",
      "Packet Delay     912\n",
      "Packet Loss      911\n",
      "CPU HOG          906\n",
      "MEM LEAK         727\n",
      "Name: count, dtype: int64\n",
      "üìå Colonnes disponibles : Index(['Unnamed: 0', 'timestamp',\n",
      "       'adservice-5dc4c759b6-w5p8z_container_cpu_usage_seconds_total',\n",
      "       'adservice-5dc4c759b6-w5p8z_container_memory_working_set_bytes',\n",
      "       'adservice-5dc4c759b6-w5p8z_container_network_transmit_packets_total',\n",
      "       'adservice-5dc4c759b6-w5p8z_deployed_at',\n",
      "       'cartservice-7f84c9f647-bltfq_container_cpu_usage_seconds_total',\n",
      "       'cartservice-7f84c9f647-bltfq_container_memory_working_set_bytes',\n",
      "       'cartservice-7f84c9f647-bltfq_container_network_transmit_packets_total',\n",
      "       'cartservice-7f84c9f647-bltfq_deployed_at',\n",
      "       ...\n",
      "       'loadgenerator-7785849b66-vhwdf_container_network_transmit_packets_total',\n",
      "       'loadgenerator-7785849b66-vhwdf_deployed_at',\n",
      "       'loadgenerator-64fb74c986-62785_container_cpu_usage_seconds_total',\n",
      "       'loadgenerator-64fb74c986-62785_container_memory_working_set_bytes',\n",
      "       'loadgenerator-64fb74c986-62785_container_network_transmit_packets_total',\n",
      "       'loadgenerator-64fb74c986-62785_deployed_at',\n",
      "       'loadgenerator-64fb74c986-9fjcn_container_cpu_usage_seconds_total',\n",
      "       'loadgenerator-64fb74c986-9fjcn_container_memory_working_set_bytes',\n",
      "       'loadgenerator-64fb74c986-9fjcn_container_network_transmit_packets_total',\n",
      "       'loadgenerator-64fb74c986-9fjcn_deployed_at'],\n",
      "      dtype='object', length=265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2581608487.py:99: DtypeWarning: Columns (29,37,88,92,96,100,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200,204,208,212,216,220,224,228,232,236,240,244,248,252,256,260,264) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"final_pod_resource_baro_dataset.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Taille du jeu de train : (5500, 263)\n",
      "‚úîÔ∏è Taille du jeu de test : (1376, 263)\n",
      "\n",
      "üîπ Entra√Ænement du mod√®le Random Forest...\n",
      "üìå Mod√®le : Random Forest\n",
      "üîπ Accuracy : 1.0000\n",
      "üîπ Rapport de classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CPU HOG       1.00      1.00      1.00       181\n",
      "    MEM LEAK       1.00      1.00      1.00       146\n",
      "      Normal       1.00      1.00      1.00       684\n",
      "Packet Delay       1.00      1.00      1.00       183\n",
      " Packet Loss       1.00      1.00      1.00       182\n",
      "\n",
      "    accuracy                           1.00      1376\n",
      "   macro avg       1.00      1.00      1.00      1376\n",
      "weighted avg       1.00      1.00      1.00      1376\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üîπ Entra√Ænement du mod√®le Decision Tree...\n",
      "üìå Mod√®le : Decision Tree\n",
      "üîπ Accuracy : 1.0000\n",
      "üîπ Rapport de classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CPU HOG       1.00      1.00      1.00       181\n",
      "    MEM LEAK       1.00      1.00      1.00       146\n",
      "      Normal       1.00      1.00      1.00       684\n",
      "Packet Delay       1.00      1.00      1.00       183\n",
      " Packet Loss       1.00      1.00      1.00       182\n",
      "\n",
      "    accuracy                           1.00      1376\n",
      "   macro avg       1.00      1.00      1.00      1376\n",
      "weighted avg       1.00      1.00      1.00      1376\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üîπ Entra√Ænement du mod√®le SVM...\n",
      "üìå Mod√®le : SVM\n",
      "üîπ Accuracy : 0.9847\n",
      "üîπ Rapport de classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CPU HOG       0.99      0.99      0.99       181\n",
      "    MEM LEAK       0.99      1.00      1.00       146\n",
      "      Normal       0.98      0.99      0.98       684\n",
      "Packet Delay       0.98      0.99      0.99       183\n",
      " Packet Loss       1.00      0.93      0.97       182\n",
      "\n",
      "    accuracy                           0.98      1376\n",
      "   macro avg       0.99      0.98      0.99      1376\n",
      "weighted avg       0.98      0.98      0.98      1376\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üîπ Entra√Ænement du mod√®le KNN...\n",
      "üìå Mod√®le : KNN\n",
      "üîπ Accuracy : 0.9906\n",
      "üîπ Rapport de classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CPU HOG       0.99      0.99      0.99       181\n",
      "    MEM LEAK       0.99      0.98      0.99       146\n",
      "      Normal       0.99      0.99      0.99       684\n",
      "Packet Delay       0.98      1.00      0.99       183\n",
      " Packet Loss       1.00      0.98      0.99       182\n",
      "\n",
      "    accuracy                           0.99      1376\n",
      "   macro avg       0.99      0.99      0.99      1376\n",
      "weighted avg       0.99      0.99      0.99      1376\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üîπ Entra√Ænement du mod√®le Naive Bayes...\n",
      "üìå Mod√®le : Naive Bayes\n",
      "üîπ Accuracy : 0.5116\n",
      "üîπ Rapport de classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CPU HOG       0.63      1.00      0.77       181\n",
      "    MEM LEAK       0.39      1.00      0.56       146\n",
      "      Normal       1.00      0.02      0.04       684\n",
      "Packet Delay       0.49      1.00      0.66       183\n",
      " Packet Loss       0.55      0.99      0.71       182\n",
      "\n",
      "    accuracy                           0.51      1376\n",
      "   macro avg       0.61      0.80      0.55      1376\n",
      "weighted avg       0.76      0.51      0.36      1376\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp                           instance  \\\n",
      "0 2025-04-21 20:44:13  aks-agentpool-42554999-vmss00000x   \n",
      "1 2025-04-21 20:44:14  aks-agentpool-42554999-vmss00000x   \n",
      "2 2025-04-21 20:44:15  aks-agentpool-42554999-vmss00000x   \n",
      "3 2025-04-21 20:44:16  aks-agentpool-42554999-vmss00000x   \n",
      "4 2025-04-21 20:44:17  aks-agentpool-42554999-vmss00000x   \n",
      "\n",
      "                              pod  container_cpu_usage_seconds_total  \\\n",
      "0  loadgenerator-64fb74c986-zxn5f                           0.040401   \n",
      "1  loadgenerator-64fb74c986-zxn5f                           0.042157   \n",
      "2  loadgenerator-64fb74c986-zxn5f                           0.043912   \n",
      "3  loadgenerator-64fb74c986-zxn5f                           0.045668   \n",
      "4  loadgenerator-64fb74c986-zxn5f                           0.040660   \n",
      "\n",
      "   container_cpu_system_seconds_total  container_memory_working_set_bytes  \\\n",
      "0                            0.003729                        2.435206e+06   \n",
      "1                            0.003872                        2.525402e+06   \n",
      "2                            0.004014                        2.615598e+06   \n",
      "3                            0.004156                        2.705795e+06   \n",
      "4                            0.003752                        2.176102e+06   \n",
      "\n",
      "   container_memory_rss  container_network_receive_bytes_total  \\\n",
      "0          2.437397e+06                           32725.837968   \n",
      "1          2.537665e+06                           34031.688346   \n",
      "2          2.637933e+06                           35337.538725   \n",
      "3          2.738202e+06                           36643.389103   \n",
      "4          2.119190e+06                           37949.239482   \n",
      "\n",
      "   container_network_transmit_packets_total Abnormality class   Microservice  \\\n",
      "0                                  9.400021            Normal  adservice_cpu   \n",
      "1                                  9.773806            Normal  adservice_cpu   \n",
      "2                                 10.147592            Normal  adservice_cpu   \n",
      "3                                 10.521377            Normal  adservice_cpu   \n",
      "4                                 10.895162            Normal  adservice_cpu   \n",
      "\n",
      "  Experiment  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "‚úÖ Fichier 'final2_dataset.csv' enregistr√© avec succ√®s !\n",
      "Les colonnes 'instance' ont √©t√© modifi√©es et le fichier a √©t√© tri√© par 'timestamp'. Le fichier a √©t√© enregistr√© sous 'final2_modified_sorted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# üìÅ Dossier principal contenant les exp√©riences\n",
    "root_dir = \"C:/Users/wassi/OneDrive/Bureau/experience\"\n",
    "\n",
    "# üìå Liste des classes valides\n",
    "valid_classes = [\"CPU HOG\", \"MEM LEAK\", \"Packet Loss\", \"Packet Delay\"]\n",
    "\n",
    "# üìå Liste pour stocker les DataFrames de chaque fichier\n",
    "df_resource_baro_list = []\n",
    "df_communication_list = []\n",
    "\n",
    "# üîç Parcours des sous-dossiers (microservices)\n",
    "for microservice in os.listdir(root_dir):\n",
    "    microservice_path = os.path.join(root_dir, microservice)\n",
    "    \n",
    "    if os.path.isdir(microservice_path):  # V√©rifier si c'est un dossier\n",
    "        # D√©terminer la classe en fonction du suffixe (_cpu, _mem, _loss, _delay)\n",
    "        if microservice.endswith(\"_cpu\"):\n",
    "            failure_class = \"CPU HOG\"\n",
    "        elif microservice.endswith(\"_mem\"):\n",
    "            failure_class = \"MEM LEAK\"\n",
    "        elif microservice.endswith(\"_loss\"):\n",
    "            failure_class = \"Packet Loss\"\n",
    "        elif microservice.endswith(\"_delay\"):\n",
    "            failure_class = \"Packet Delay\"\n",
    "        else:\n",
    "            failure_class = \"Normal\"  # Si aucun suffixe sp√©cifique n'est trouv√©\n",
    "        \n",
    "        # üîç Parcours des exp√©riences (1,2,3,4,5)\n",
    "        for experiment in os.listdir(microservice_path):\n",
    "            experiment_path = os.path.join(microservice_path, experiment)\n",
    "            \n",
    "            if os.path.isdir(experiment_path): \n",
    "                # üìå Charger le fichier \"pod_resource_baro.csv\" s'il existe\n",
    "                data_file = os.path.join(experiment_path, \"pod_resource_baro.csv\")\n",
    "                \n",
    "                if os.path.exists(data_file):\n",
    "                    df = pd.read_csv(data_file)\n",
    "                    # Convertir la colonne \"timestamp\" en format datetime avec le format ISO 8601\n",
    "                    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                    # R√©cup√©rer le timestamp de la premi√®re ligne et ajouter 3 minutes (180 secondes)\n",
    "                    first_timestamp = df[\"timestamp\"].iloc[0]\n",
    "                    inject_time = first_timestamp + timedelta(minutes=3)\n",
    "                    \n",
    "                    # üè∑ Ajouter la classe en fonction de l'injection\n",
    "                    df[\"Abnormality class\"] = df[\"timestamp\"].apply(\n",
    "                        lambda x: \"Normal\" if x < inject_time else failure_class)\n",
    "                    \n",
    "                    # üè∑ Ajouter des colonnes pour identifier l'exp√©rience\n",
    "                    df[\"Microservice\"] = microservice\n",
    "                    df[\"Experiment\"] = experiment\n",
    "                    \n",
    "                    # üìå Ajouter le DataFrame √† la liste des fichiers pod_resource_baro\n",
    "                    df_resource_baro_list.append(df)\n",
    "\n",
    "                # üìå Charger et concat√©ner tous les fichiers \"pod_communication.csv\" sans modification\n",
    "                comm_file = os.path.join(experiment_path, \"pod_communication.csv\")\n",
    "                if os.path.exists(comm_file):\n",
    "                    comm_df = pd.read_csv(comm_file)\n",
    "                    comm_df[\"Microservice\"] = microservice\n",
    "                    comm_df[\"Experiment\"] = experiment\n",
    "                    # üìå Ajouter le DataFrame √† la liste des fichiers pod_communication\n",
    "                    df_communication_list.append(comm_df)\n",
    "\n",
    "# üèó Fusionner tous les DataFrames en un seul pour pod_resource_baro\n",
    "df_resource_baro_all = pd.concat(df_resource_baro_list, ignore_index=True)\n",
    "\n",
    "# üèó Fusionner tous les DataFrames en un seul pour pod_communication\n",
    "df_communication_all = pd.concat(df_communication_list, ignore_index=True)\n",
    "\n",
    "# üîé Affichage de quelques lignes pour v√©rification\n",
    "print(df_resource_baro_all.head())\n",
    "print(df_communication_all.head())\n",
    "\n",
    "# üìÇ Sauvegarde des DataFrames finaux\n",
    "df_resource_baro_all.to_csv(\"final_pod_resource_baro_dataset.csv\", index=False)\n",
    "df_communication_all.to_csv(\"final_pod_communication_dataset.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Fichiers 'final_pod_resource_baro_dataset.csv' et 'final_pod_communication_dataset.csv' enregistr√©s avec succ√®s !\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# üìÇ Charger le dataset\n",
    "df = pd.read_csv(\"final_pod_resource_baro_dataset.csv\")\n",
    "\n",
    "# üîé V√©rifier la distribution des classes\n",
    "print(\"üìå Distribution des classes :\\n\", df[\"Abnormality class\"].value_counts())\n",
    "\n",
    "# üéØ D√©finir X (features) et y (target)\n",
    "print(\"üìå Colonnes disponibles :\", df.columns)\n",
    "X = df.drop(columns=[\"Abnormality class\", \"Experiment\"], errors=\"ignore\")\n",
    "y = df[\"Abnormality class\"]\n",
    "\n",
    "# üé≠ Encodage des labels (y)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# üîÑ Convert non-numeric columns to numeric\n",
    "non_numeric_columns = X.select_dtypes(include=['object']).columns\n",
    "for col in non_numeric_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# üö® Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# üé≤ S√©parer en train & test (80% train, 20% test) avec stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# üî¨ Normalisation des features (important pour SVM et KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ‚úÖ V√©rification\n",
    "print(f\"‚úîÔ∏è Taille du jeu de train : {X_train.shape}\")\n",
    "print(f\"‚úîÔ∏è Taille du jeu de test : {X_test.shape}\")\n",
    "\n",
    "# üìå Initialisation des mod√®les\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# üî• Entra√Ænement et √©valuation des mod√®les\n",
    "accuracies = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîπ Entra√Ænement du mod√®le {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # üéØ Stocker l'accuracy\n",
    "    accuracies[name] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # üìä Affichage des r√©sultats\n",
    "    print(f\"üìå Mod√®le : {name}\")\n",
    "    print(f\"üîπ Accuracy : {accuracies[name]:.4f}\")\n",
    "    print(f\"üîπ Rapport de classification : \\n{classification_report(y_test, y_pred, target_names=label_encoder.classes_)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# üìä Tracer les r√©sultats\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'orange', 'green', 'red', 'purple'])\n",
    "plt.xlabel(\"Mod√®les\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Performance des Mod√®les de Machine Learning\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# üìÅ Dossier principal contenant les exp√©riences\n",
    "root_dir = \"C:/Users/wassi/OneDrive/Bureau/experience\"\n",
    "\n",
    "# üìå Liste des classes valides\n",
    "valid_classes = [\"CPU HOG\", \"MEM LEAK\", \"Packet Loss\", \"Packet Delay\"]\n",
    "\n",
    "# üìå Liste pour stocker les DataFrames de chaque fichier\n",
    "df_list = []\n",
    "\n",
    "# üîç Parcours des sous-dossiers (microservices)\n",
    "for microservice in os.listdir(root_dir):\n",
    "    microservice_path = os.path.join(root_dir, microservice)\n",
    "    \n",
    "    if os.path.isdir(microservice_path):  # V√©rifier si c'est un dossier\n",
    "        # D√©terminer la classe en fonction du suffixe (_cpu, _mem, _loss, _delay)\n",
    "        if microservice.endswith(\"_cpu\"):\n",
    "            failure_class = \"CPU HOG\"\n",
    "        elif microservice.endswith(\"_mem\"):\n",
    "            failure_class = \"MEM LEAK\"\n",
    "        elif microservice.endswith(\"_loss\"):\n",
    "            failure_class = \"Packet Loss\"\n",
    "        elif microservice.endswith(\"_delay\"):\n",
    "            failure_class = \"Packet Delay\"\n",
    "        else:\n",
    "            failure_class = \"Normal\"  # Si aucun suffixe sp√©cifique n'est trouv√©\n",
    "        \n",
    "        # üîç Parcours des exp√©riences (1,2,3,4,5)\n",
    "        for experiment in os.listdir(microservice_path):\n",
    "            experiment_path = os.path.join(microservice_path, experiment)\n",
    "            \n",
    "            if os.path.isdir(experiment_path): \n",
    "                # üìå Charger le fichier \"data.csv\" s'il existe\n",
    "                data_file = os.path.join(experiment_path, \"pod_resource_consumption.csv\")\n",
    "                \n",
    "                if os.path.exists(data_file):\n",
    "                    df = pd.read_csv(data_file)\n",
    "                    # Convertir la colonne \"timestamp\" en format datetime avec le format ISO 8601\n",
    "                    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "                    # R√©cup√©rer le timestamp de la premi√®re ligne et ajouter 3 minutes (180 secondes)\n",
    "                    first_timestamp = df[\"timestamp\"].iloc[0]\n",
    "                    inject_time = first_timestamp + timedelta(minutes=3)\n",
    "                    \n",
    "                    # üè∑ Ajouter la classe en fonction de l'injection\n",
    "                    df[\"Abnormality class\"] = df[\"timestamp\"].apply(\n",
    "                        lambda x: \"Normal\" if x < inject_time else failure_class)\n",
    "                    \n",
    "                    # üè∑ Ajouter des colonnes pour identifier l'exp√©rience\n",
    "                    df[\"Microservice\"] = microservice\n",
    "                    df[\"Experiment\"] = experiment\n",
    "                    \n",
    "                    # üìå Ajouter le DataFrame √† la liste\n",
    "                    df_list.append(df)\n",
    "\n",
    "# üèó Fusionner tous les DataFrames en un seul\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# üîé Affichage de quelques lignes pour v√©rification\n",
    "print(df_all.head())\n",
    "\n",
    "# üìÇ Sauvegarde du DataFrame final\n",
    "df_all.to_csv(\"final2_dataset.csv\", index=False)\n",
    "print(\"‚úÖ Fichier 'final2_dataset.csv' enregistr√© avec succ√®s !\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = pd.read_csv('final2_dataset.csv')\n",
    "\n",
    "# Parcourir toutes les colonnes qui se terminent par \"_deployed_at\"\n",
    "for col in df.columns:\n",
    "    if col.endswith('instance'):\n",
    "        # Parcourir toutes les lignes de la colonne et modifier chaque valeur\n",
    "        for i in range(len(df)):\n",
    "            current_value = df.at[i, col]  # R√©cup√©rer la valeur actuelle de la cellule\n",
    "            if pd.notna(current_value):  # V√©rifier si la cellule n'est pas vide (NaN)\n",
    "                current_value_str = str(current_value)  # Convertir en cha√Æne si n√©cessaire\n",
    "                # Modifier la valeur en \"node\" + les deux derniers caract√®res de la valeur\n",
    "                df.at[i, col] = 'node' + current_value_str[-2:]\n",
    "\n",
    "# Trier le DataFrame par la colonne 'timestamp'\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "# Sauvegarder le fichier avec les nouvelles modifications et tri√© par 'timestamp'\n",
    "df.to_csv('final2_modified_sorted.csv', index=False)\n",
    "\n",
    "print(\"Les colonnes 'instance' ont √©t√© modifi√©es et le fichier a √©t√© tri√© par 'timestamp'. Le fichier a √©t√© enregistr√© sous 'final2_modified_sorted.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2278a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['grpc_response_status'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_success['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_error['latency'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement termin√©. Fichier sauvegard√© sous 'new_request_istio_data.csv'.\n",
      "Traitement termin√©. Fichier sauvegard√© sous aggregated_istio_rates.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:195: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  .resample(window, on='timestamp', label='right', closed='right')\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:235: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:195: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  .resample(window, on='timestamp', label='right', closed='right')\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:235: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:235: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:235: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2960753219.py:235: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(compute_real_durations)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger le fichier CSV\n",
    "file_path = \"final_pod_communication_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['grpc_response_status'].fillna(0, inplace=True)\n",
    "\n",
    "df['response_flags'] = df['response_flags'].astype(str).str.strip()  # Convertir en string et enlever espaces\n",
    "\n",
    "# Ajouter une colonne 'result' avec 'success' ou 'error'\n",
    "df['result'] = df.apply(\n",
    "    lambda row: 'success' if row['response_code'] == 200 and row['grpc_response_status'] == 0 and row['response_flags'] == '-' else 'error',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# R√©organiser les donn√©es par 'source_workload', 'destination_workload' et 'timestamp'\n",
    "df_sorted = df.sort_values(by=['source_workload', 'destination_workload', 'timestamp'])\n",
    "\n",
    "# Sauvegarder le fichier r√©sultant\n",
    "df_sorted.to_csv(\"aggregated_istio_data.csv\", index=False)\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"aggregated_istio_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir timestamp en datetime pour le tri\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Trier avant la s√©paration\n",
    "df.sort_values(by=['source_workload', 'destination_workload', 'timestamp'], inplace=True)\n",
    "\n",
    "# S√©parer les succ√®s\n",
    "df_success = df[df['result'] == 'success'].copy()\n",
    "\n",
    "# Calculer new_request, new_istio_request_bytes et new_istio_request_duration_milliseconds avec 0 pour la premi√®re ligne\n",
    "df_success['new_request'] = df_success.groupby(['source_workload', 'destination_workload'])['total_request'].diff().fillna(0)\n",
    "df_success['new_istio_request_bytes'] = df_success.groupby(['source_workload', 'destination_workload'])['istio_request_bytes_sum'].diff().fillna(0)\n",
    "df_success['new_istio_request_duration_milliseconds'] = df_success.groupby(['source_workload', 'destination_workload'])['istio_request_duration_milliseconds_sum'].diff().fillna(0)\n",
    "\n",
    "# Appliquer la condition si new_request == 0\n",
    "df_success.loc[df_success['new_request'] == 0, ['new_istio_request_bytes', 'new_istio_request_duration_milliseconds']] = 0\n",
    "\n",
    "# Calculer latency\n",
    "df_success['latency'] = df_success['new_istio_request_duration_milliseconds'] / df_success['new_request']\n",
    "df_success['latency'].fillna(0, inplace=True)\n",
    "\n",
    "# Sauvegarder les succ√®s dans un fichier\n",
    "df_success.to_csv(\"success_istio_data.csv\", index=False)\n",
    "\n",
    "# S√©parer les erreurs HTTP et gRPC\n",
    "df_http_errors = df[(df['result'] == 'error') & (df['request_protocol'] == 'http')].copy()\n",
    "df_grpc_errors = df[(df['result'] == 'error') & (df['request_protocol'] == 'grpc')].copy()\n",
    "\n",
    "error_files = []  # Liste des fichiers d'erreur g√©n√©r√©s\n",
    "\n",
    "# Traitement des erreurs HTTP\n",
    "http_groups = df_http_errors.groupby(['request_protocol', 'response_code', 'grpc_response_status', 'response_flags'])\n",
    "\n",
    "for (request_protocol, response_code, grpc_status, response_flags), df_error in http_groups:\n",
    "    df_error = df_error.copy()\n",
    "    \n",
    "    # Calculer new_request, new_istio_request_bytes et new_istio_request_duration_milliseconds avec 0 pour la premi√®re ligne\n",
    "    df_error['new_request'] = df_error.groupby(['source_workload', 'destination_workload'])['total_request'].diff().fillna(0)\n",
    "    df_error['new_istio_request_bytes'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_bytes_sum'].diff().fillna(0)\n",
    "    df_error['new_istio_request_duration_milliseconds'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_duration_milliseconds_sum'].diff().fillna(0)\n",
    "    \n",
    "    # Appliquer la condition si new_request == 0\n",
    "    df_error.loc[df_error['new_request'] == 0, ['new_istio_request_bytes', 'new_istio_request_duration_milliseconds']] = 0\n",
    "    \n",
    "    # Calculer latency\n",
    "    df_error['latency'] = df_error['new_istio_request_duration_milliseconds'] / df_error['new_request']\n",
    "    df_error['latency'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Nommer le fichier selon l'erreur\n",
    "    file_name = f\"error_{request_protocol}_{response_code}_{response_flags}.csv\"\n",
    "    df_error.to_csv(file_name, index=False)\n",
    "    error_files.append(df_error)\n",
    "\n",
    "# Traitement des erreurs gRPC\n",
    "grpc_groups = df_grpc_errors.groupby(['request_protocol', 'response_code', 'grpc_response_status', 'response_flags'])\n",
    "\n",
    "for (request_protocol, response_code, grpc_status, response_flags), df_error in grpc_groups:\n",
    "    df_error = df_error.copy()\n",
    "    \n",
    "    # Calculer new_request, new_istio_request_bytes et new_istio_request_duration_milliseconds avec 0 pour la premi√®re ligne\n",
    "    df_error['new_request'] = df_error.groupby(['source_workload', 'destination_workload'])['total_request'].diff().fillna(0)\n",
    "    df_error['new_istio_request_bytes'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_bytes_sum'].diff().fillna(0)\n",
    "    df_error['new_istio_request_duration_milliseconds'] = df_error.groupby(['source_workload', 'destination_workload'])['istio_request_duration_milliseconds_sum'].diff().fillna(0)\n",
    "    \n",
    "    # Appliquer la condition si new_request == 0\n",
    "    df_error.loc[df_error['new_request'] == 0, ['new_istio_request_bytes', 'new_istio_request_duration_milliseconds']] = 0\n",
    "    \n",
    "    # Calculer latency\n",
    "    df_error['latency'] = df_error['new_istio_request_duration_milliseconds'] / df_error['new_request']\n",
    "    df_error['latency'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Nommer le fichier selon l'erreur\n",
    "    file_name = f\"error_{request_protocol}_{response_code}_{grpc_status}_{response_flags}.csv\"\n",
    "    df_error.to_csv(file_name, index=False)\n",
    "    error_files.append(df_error)\n",
    "\n",
    "# Fusionner tous les fichiers (success + errors)\n",
    "df_final = pd.concat([df_success] + error_files).sort_values(by=['source_workload', 'destination_workload', 'timestamp'])\n",
    "\n",
    "# Sauvegarder le fichier final\n",
    "df_final.to_csv(\"new_request_istio_data.csv\", index=False)\n",
    "\n",
    "print(\"Traitement termin√©. Fichier sauvegard√© sous 'new_request_istio_data.csv'.\")\n",
    "\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"new_request_istio_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Trier les donn√©es\n",
    "df.sort_values(by=['source_workload', 'destination_workload', 'timestamp'], inplace=True)\n",
    "\n",
    "# Calculer success rate, error rate, etc.\n",
    "grouped = df.groupby(['source_workload', 'destination_workload', 'timestamp'])\n",
    "aggregated_rows = []\n",
    "\n",
    "for (src, dst, ts), group in grouped:\n",
    "    total_new_request = group['new_request'].sum()\n",
    "    success_count = group[group['result'] == 'success']['new_request'].sum()\n",
    "    error_count = total_new_request - success_count\n",
    "    \n",
    "    if total_new_request > 0:\n",
    "        success_rate = success_count / total_new_request\n",
    "        error_rate = 1 - success_rate\n",
    "    else:\n",
    "        success_rate = float('nan')\n",
    "        error_rate = float('nan')\n",
    "    \n",
    "    duration_success_request = group[group['result'] == 'success']['latency'].sum()\n",
    "    duration_error_request = group[group['result'] == 'error']['latency'].sum()\n",
    "    average_latency = duration_success_request + duration_error_request\n",
    "\n",
    "    new_istio_request_bytes_success = group[group['result'] == 'success']['new_istio_request_bytes'].sum()\n",
    "    new_istio_request_bytes_error = group[group['result'] == 'error']['new_istio_request_bytes'].sum()\n",
    "    istio_request_bytes = new_istio_request_bytes_success + new_istio_request_bytes_error\n",
    "    istio_request_duration_milliseconds = group['new_istio_request_duration_milliseconds'].sum()\n",
    "\n",
    "    # R√©cup√©rer la valeur du node (par exemple le premier)\n",
    "    node = group['node'].iloc[0] if 'node' in group.columns else None\n",
    "\n",
    "    aggregated_rows.append([\n",
    "        ts, src, dst, node, group['total_request'].max(), total_new_request,\n",
    "        success_count, error_count, success_rate, error_rate,\n",
    "        duration_success_request, duration_error_request, average_latency,\n",
    "        new_istio_request_bytes_success, new_istio_request_bytes_error,\n",
    "        istio_request_bytes, istio_request_duration_milliseconds\n",
    "    ])\n",
    "\n",
    "# Cr√©er un DataFrame final\n",
    "df_final = pd.DataFrame(aggregated_rows, columns=[\n",
    "    'timestamp', 'source_workload', 'destination_workload', 'node', 'total_request', 'new_request',\n",
    "    'success_count', 'error_count', 'success_rate', 'error_rate',\n",
    "    'duration_success_request', 'duration_error_request', 'average_latency',\n",
    "    'new_istio_request_bytes_success', 'new_istio_request_bytes_error',\n",
    "    'istio_request_bytes', 'duration_milliseconds'\n",
    "])\n",
    "\n",
    "# Sauvegarder le fichier\n",
    "output_file = \"aggregated_istio_rates.csv\"\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Traitement termin√©. Fichier sauvegard√© sous {output_file}.\")\n",
    "\n",
    "\n",
    "\n",
    "# Charger le fichier\n",
    "file_path = \"aggregated_istio_rates.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convertir timestamp en datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# D√©finir les fen√™tres de temps\n",
    "time_windows = ['15S', '30S', '1min', '5min', '10min']\n",
    "\n",
    "# Initialiser un tableau pour stocker les r√©sultats\n",
    "kpi_results = []\n",
    "\n",
    "for window in time_windows:\n",
    "    # Resample par fen√™tre de temps\n",
    "    df_resampled = (\n",
    "        df\n",
    "        .groupby(['source_workload', 'destination_workload'])\n",
    "        .resample(window, on='timestamp', label='right', closed='right')\n",
    "        .agg({\n",
    "            'total_request': 'max',\n",
    "            'new_request': 'sum',\n",
    "            'success_count': 'sum',\n",
    "            'error_count': 'sum',\n",
    "            'success_rate': 'mean',\n",
    "            'error_rate': 'mean',\n",
    "            'average_latency': 'sum',\n",
    "            'istio_request_bytes': 'sum',\n",
    "            'duration_milliseconds': 'sum'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Pour chaque pair source-destination, calculer la vraie dur√©e entre deux points non nuls\n",
    "    def compute_real_durations(group):\n",
    "        # Garder le timestamp courant pour r√©f√©rence\n",
    "        last_time = None\n",
    "        last_index = None\n",
    "        durations = []\n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            if row['new_request'] > 0:\n",
    "                if last_time is not None:\n",
    "                    duration = (row['timestamp'] - last_time).total_seconds()\n",
    "                    durations.append(duration)\n",
    "                else:\n",
    "                    durations.append(np.nan)\n",
    "                last_time = row['timestamp']\n",
    "                last_index = idx\n",
    "            else:\n",
    "                durations.append(np.nan)\n",
    "        # Remplir les valeurs manquantes en regardant en avant\n",
    "        return pd.Series(durations, index=group.index)\n",
    "\n",
    "    # Appliquer la fonction √† chaque groupe\n",
    "    df_resampled['real_duration'] = (\n",
    "        df_resampled\n",
    "        .groupby(['source_workload', 'destination_workload'])\n",
    "        .apply(compute_real_durations)\n",
    "        .reset_index(level=[0,1], drop=True)\n",
    "    )\n",
    "\n",
    "    # Calcul des KPI\n",
    "    df_resampled['throughput'] = df_resampled['istio_request_bytes'] / df_resampled['real_duration']\n",
    "    df_resampled['request_rate'] = df_resampled['new_request'] / df_resampled['real_duration']\n",
    "\n",
    "    # Ajouter la fen√™tre utilis√©e\n",
    "    df_resampled['time_window'] = window\n",
    "\n",
    "    kpi_results.append(df_resampled)\n",
    "\n",
    "# Concat√©ner tous les r√©sultats\n",
    "df_final = pd.concat(kpi_results)\n",
    "\n",
    "# Supprimer la ligne o√π timestamp == \"2025-04-02 15:21:00\"\n",
    "starting_point = pd.Timestamp(\"2025-04-08 00:15:00\")\n",
    "df_final = df_final[df_final['timestamp'] != starting_point]\n",
    "\n",
    "# Sauvegarder dans un fichier CSV\n",
    "df_final.to_csv(\"kiali_kpi_metrics.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9158c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Entra√Ænement du mod√®le GAE...\n",
      "Epoch 20, Loss: 1.2514\n",
      "Epoch 40, Loss: 1.2229\n",
      "Epoch 60, Loss: 1.1305\n",
      "Epoch 80, Loss: 1.0917\n",
      "Epoch 100, Loss: 1.0395\n",
      "Epoch 120, Loss: 1.1759\n",
      "Epoch 140, Loss: 0.9896\n",
      "Epoch 160, Loss: 1.1517\n",
      "Epoch 180, Loss: 1.0310\n",
      "Epoch 200, Loss: 0.9258\n",
      "‚úÖ Fichier anomaly_scores_filtered.csv g√©n√©r√©.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import remove_self_loops, to_undirected\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# üîÑ Chargement des donn√©es\n",
    "df = pd.read_csv(\"kiali_kpi_metrics.csv\")\n",
    "\n",
    "# üßΩ Nettoyage de time_window\n",
    "df['time_window'] = df['time_window'].astype(str).str.strip()\n",
    "df = df[df['time_window'] == \"15S\"].copy()\n",
    "\n",
    "if df.empty:\n",
    "    raise ValueError(\"üö® Aucun enregistrement avec time_window == '15s'. V√©rifiez le fichier CSV.\")\n",
    "\n",
    "# ‚úÖ Nettoyage des colonnes num√©riques\n",
    "df['error_rate'] = pd.to_numeric(df['error_rate'], errors='coerce').fillna(0.0)\n",
    "\n",
    "# üè∑Ô∏è Attribution du statut\n",
    "def assign_status(er):\n",
    "    if er == 0.0:\n",
    "        return \"Healthy\"\n",
    "    elif er < 0.15:\n",
    "        return \"Degraded\"\n",
    "    else:\n",
    "        return \"Unavailable\"\n",
    "\n",
    "df['status'] = df['error_rate'].apply(assign_status)\n",
    "\n",
    "# üîç Pr√©paration des donn√©es pour le mod√®le (uniquement anomalies)\n",
    "df_anomalies = df[df['status'] != \"Healthy\"].copy()\n",
    "\n",
    "# Cr√©ation des n≈ìuds\n",
    "nodes = pd.unique(df[['source_workload', 'destination_workload']].values.ravel())\n",
    "node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "idx_to_node = {v: k for k, v in node_to_idx.items()}\n",
    "\n",
    "# Cr√©ation de edge_index (pour les anomalies uniquement)\n",
    "edge_index = torch.tensor([\n",
    "    [node_to_idx[src] for src in df_anomalies['source_workload']],\n",
    "    [node_to_idx[dst] for dst in df_anomalies['destination_workload']],\n",
    "], dtype=torch.long)\n",
    "\n",
    "edge_index, _ = remove_self_loops(edge_index)\n",
    "edge_index = to_undirected(edge_index)\n",
    "\n",
    "# Features des n≈ìuds (moyenne de error_rate par source)\n",
    "features = df.groupby('source_workload')['error_rate'].mean().reindex(nodes).fillna(0)\n",
    "scaler = StandardScaler()\n",
    "x = torch.tensor(scaler.fit_transform(features.values.reshape(-1, 1)), dtype=torch.float)\n",
    "x = torch.nan_to_num(x)\n",
    "\n",
    "# üß± Donn√©es pour le GCN\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# === GCN Autoencoder ===\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "# Mod√®le GAE\n",
    "model = GAE(GCNEncoder(data.num_node_features, 16))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Entra√Ænement\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    loss = model.recon_loss(z, data.edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "print(\"üîÅ Entra√Ænement du mod√®le GAE...\")\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Encodage final\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    probs = model.decoder.forward_all(z).sigmoid()\n",
    "\n",
    "# Calcul des scores d'anomalie\n",
    "scores = []\n",
    "for idx, row in df.iterrows():\n",
    "    src = node_to_idx.get(row['source_workload'])\n",
    "    dst = node_to_idx.get(row['destination_workload'])\n",
    "\n",
    "    if row['status'] == \"Healthy\":\n",
    "        score = 0.0  # Pas d'anomalie pour les communications saines\n",
    "    elif src is not None and dst is not None:\n",
    "        score = 1.0 - probs[src, dst].item()  # Calcul du score d'anomalie bas√© sur la reconstruction\n",
    "    else:\n",
    "        score = 1.0  # par d√©faut en cas de noeud inconnu\n",
    "    scores.append(score)\n",
    "\n",
    "df['anomaly_score'] = scores\n",
    "df.to_csv(\"anomaly_scores_filtered.csv\", index=False)\n",
    "print(\"‚úÖ Fichier anomaly_scores_filtered.csv g√©n√©r√©.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0a48fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\2878623855.py:27: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df['minute'] = df['timestamp'].dt.floor('T')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF enregistr√© sous 'temporal_anomaly_graph.gif' !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "\n",
    "# Charger les donn√©es\n",
    "df = pd.read_csv(\"anomaly_scores_filtered.csv\")\n",
    "\n",
    "# V√©rification des colonnes n√©cessaires\n",
    "required_columns = ['timestamp', 'source_workload', 'destination_workload', 'status', 'anomaly_score', 'time_window']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise ValueError(f\"Le fichier CSV doit contenir les colonnes suivantes : {', '.join(required_columns)}\")\n",
    "\n",
    "# Nettoyage\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df['time_window'] = df['time_window'].astype(str).str.strip()\n",
    "\n",
    "# Filtrage time_window contenant \"15\"\n",
    "df = df[df['time_window'].str.contains(\"15\", case=False, na=False)].copy()\n",
    "if df.empty:\n",
    "    raise ValueError(\"üö® Aucun enregistrement avec time_window contenant '15'.\")\n",
    "\n",
    "# Ajouter la minute\n",
    "df['minute'] = df['timestamp'].dt.floor('T')\n",
    "\n",
    "# Fonction pour colorier les ar√™tes\n",
    "def get_color(status):\n",
    "    return {\n",
    "        'Healthy': 'green',\n",
    "        'Degraded': 'blue',\n",
    "        'Unavailable': 'red'\n",
    "    }.get(status, 'gray')\n",
    "\n",
    "# Initialisation\n",
    "grouped = df.groupby('minute')\n",
    "frames = []  # pour stocker les images de chaque frame\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "\n",
    "# Disposition fixe pour tout (optionnel) pour √©viter saut de n≈ìuds\n",
    "fixed_pos = {}\n",
    "\n",
    "# Construire chaque minute\n",
    "minutes = sorted(grouped.groups.keys())\n",
    "\n",
    "def build_graph(minute):\n",
    "    G = nx.DiGraph()\n",
    "    group = grouped.get_group(minute)\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        src = row['source_workload']\n",
    "        dst = row['destination_workload']\n",
    "        color = get_color(row['status'])\n",
    "        score = row['anomaly_score']\n",
    "        label = f\"{score:.2f}\" if score > 0.0 else \"\"\n",
    "\n",
    "        G.add_node(src)\n",
    "        G.add_node(dst)\n",
    "        G.add_edge(src, dst, color=color, score=score, label=label)\n",
    "\n",
    "    return G\n",
    "\n",
    "# Fonction d'animation\n",
    "def update(i):\n",
    "    ax.clear()\n",
    "    minute = minutes[i]\n",
    "    G = build_graph(minute)\n",
    "\n",
    "    global fixed_pos\n",
    "    if not fixed_pos:\n",
    "        fixed_pos = nx.spring_layout(G, seed=84, k=0.5, iterations=50)\n",
    "\n",
    "    nx.draw_networkx_nodes(G, fixed_pos, node_size=600, node_color='skyblue', ax=ax)\n",
    "\n",
    "    edge_colors = [G[u][v]['color'] for u, v in G.edges()]\n",
    "    nx.draw_networkx_edges(G, fixed_pos, edge_color=edge_colors, width=2, ax=ax)\n",
    "\n",
    "    nx.draw_networkx_labels(G, fixed_pos, font_size=10, font_weight='bold', ax=ax)\n",
    "\n",
    "    edge_labels = {\n",
    "        (u, v): f\"{G[u][v]['label']}\" for u, v in G.edges()\n",
    "        if G[u][v]['label']\n",
    "    }\n",
    "    label_pos = {k: (v[0], v[1] + 0.03) for k, v in fixed_pos.items()}\n",
    "    nx.draw_networkx_edge_labels(G, pos=label_pos, edge_labels=edge_labels, font_size=9, font_color='black', ax=ax)\n",
    "\n",
    "    legend = [\n",
    "        Line2D([0], [0], color='green', lw=2, label='Healthy'),\n",
    "        Line2D([0], [0], color='blue', lw=2, label='Degraded'),\n",
    "        Line2D([0], [0], color='red', lw=2, label='Unavailable'),\n",
    "    ]\n",
    "    ax.legend(handles=legend, loc='upper right')\n",
    "\n",
    "    ax.set_title(f\"Graphe minute {minute.strftime('%Y-%m-%d %H:%M')}\", fontsize=14)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Cr√©er l'animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(minutes), interval=1000, repeat=False)\n",
    "\n",
    "# Sauvegarder en GIF\n",
    "ani.save('temporal_anomaly_graph.gif', writer='pillow', fps=1)\n",
    "\n",
    "print(\"‚úÖ GIF enregistr√© sous 'temporal_anomaly_graph.gif' !\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd17eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "C:\\Users\\wassi\\AppData\\Local\\Temp\\ipykernel_15516\\3932223751.py:78: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF enregistr√© sous : knowledge_graph_evolution.gif\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# ‚úÖ Charger les donn√©es\n",
    "df = pd.read_csv('final2_modified_sorted.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['Microservice'] = df['Microservice'].astype(str)\n",
    "\n",
    "# ‚úÖ Cr√©er dossier pour images\n",
    "os.makedirs('frames', exist_ok=True)\n",
    "frame_files = []  # stocke les noms d'images\n",
    "\n",
    "# ‚úÖ Fonction pour construire un graphe pour une p√©riode donn√©e\n",
    "def create_knowledge_graph(df, start_time, end_time):\n",
    "    filtered_df = df[(df['timestamp'] >= start_time) & (df['timestamp'] < end_time)]\n",
    "    G = nx.DiGraph()\n",
    "    microservice_name = None\n",
    "    attack_type = None\n",
    "\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        if pd.isna(row['Microservice']):\n",
    "            continue\n",
    "\n",
    "        microservice = row['Microservice']\n",
    "        try:\n",
    "            microservice_name, attack_type = microservice.split('_')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        instance = row['instance']\n",
    "        pod = row['pod']\n",
    "        G.add_node(instance, type='instance')\n",
    "        G.add_node(pod, type='pod')\n",
    "\n",
    "        if row['Abnormality class'] == 'Normal':\n",
    "            edge_color = 'green'\n",
    "        else:\n",
    "            edge_color = 'red'\n",
    "\n",
    "        # Ajouter ar√™te g√©n√©rale\n",
    "        G.add_edge(instance, pod, color='green', anomaly='Normal')\n",
    "\n",
    "        # Ajouter ar√™te rouge si anomalie d√©tect√©e sur le bon pod\n",
    "        if microservice_name in pod:\n",
    "            G.add_edge(instance, pod, color=edge_color, anomaly=row['Abnormality class'])\n",
    "\n",
    "    return G, microservice_name, attack_type, row['Abnormality class']\n",
    "\n",
    "# ‚úÖ Fonction pour tracer et enregistrer une image\n",
    "def save_graph(G, start_time, end_time, microservice_name, attack_type, anomaly_class, frame_id):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    edge_colors = [G[u][v]['color'] for u, v in G.edges()]\n",
    "    pos = nx.spring_layout(G, seed=84)\n",
    "\n",
    "    nx.draw(G, pos, with_labels=True, node_size=1000, node_color='lightblue',\n",
    "            font_size=7, edge_color=edge_colors, width=2, font_weight='bold')\n",
    "\n",
    "    plt.title(f\"Graph from {start_time} to {end_time}\", fontsize=14)\n",
    "\n",
    "    # L√©gende\n",
    "    red_patch = plt.Line2D([0], [0], marker='o', color='w', label='Anomalie', markerfacecolor='red', markersize=10)\n",
    "    green_patch = plt.Line2D([0], [0], marker='o', color='w', label='Normal', markerfacecolor='green', markersize=10)\n",
    "    plt.legend(handles=[red_patch, green_patch])\n",
    "\n",
    "    # Texte sous le graphe\n",
    "    if anomaly_class != 'Normal':\n",
    "        plt.figtext(0.5, 0.01, f\"Microservice attaqu√© : {microservice_name}, Type : {attack_type.upper()}\",\n",
    "                    wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    else:\n",
    "        plt.figtext(0.5, 0.01, \"Aucune attaque d√©tect√©e\",\n",
    "                    wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "    # Bien cadrer le texte\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Sauvegarde image\n",
    "    filename = f'frames/frame_{frame_id:03}.png'\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    frame_files.append(filename)\n",
    "\n",
    "# ‚úÖ Identifier les exp√©riences\n",
    "df['microservice_change'] = df['Microservice'].ne(df['Microservice'].shift()).cumsum()\n",
    "\n",
    "# ‚úÖ G√©n√©rer tous les graphes\n",
    "frame_id = 0\n",
    "for exp_id, exp_df in df.groupby('microservice_change'):\n",
    "    start_time = exp_df['timestamp'].min()\n",
    "    end_time = start_time + timedelta(minutes=6)\n",
    "\n",
    "    # Avant injection\n",
    "    G1, microservice_name, attack_type, anomaly_class = create_knowledge_graph(\n",
    "        exp_df, start_time, start_time + timedelta(minutes=3))\n",
    "    save_graph(G1, start_time, start_time + timedelta(minutes=3),\n",
    "               microservice_name, attack_type, anomaly_class, frame_id)\n",
    "    frame_id += 1\n",
    "\n",
    "    # Apr√®s injection\n",
    "    G2, _, _, _ = create_knowledge_graph(\n",
    "        exp_df, start_time + timedelta(minutes=3), end_time)\n",
    "    save_graph(G2, start_time + timedelta(minutes=3), end_time,\n",
    "               microservice_name, attack_type, anomaly_class, frame_id)\n",
    "    frame_id += 1\n",
    "\n",
    "# ‚úÖ G√©n√©rer le GIF\n",
    "images = [Image.open(f) for f in frame_files]\n",
    "images[0].save('knowledge_graph_evolution.gif', save_all=True,\n",
    "               append_images=images[1:], duration=1500, loop=0)\n",
    "\n",
    "print(\"‚úÖ GIF enregistr√© sous : knowledge_graph_evolution.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e712056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GIF saved as 'combined_graph6.gif'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "df1 = pd.read_csv(\"anomaly_scores_filtered.csv\")\n",
    "df2 = pd.read_csv(\"final2_modified_sorted.csv\")\n",
    "\n",
    "# Required columns\n",
    "required_cols1 = ['source_workload', 'destination_workload', 'timestamp', 'status', 'anomaly_score']\n",
    "required_cols2 = ['timestamp', 'instance', 'pod', 'Abnormality class', 'Microservice']\n",
    "if not all(col in df1.columns for col in required_cols1):\n",
    "    raise ValueError(f\"anomaly_scores_filtered.csv must contain: {', '.join(required_cols1)}\")\n",
    "if not all(col in df2.columns for col in required_cols2):\n",
    "    raise ValueError(f\"final2_modified_sorted.csv must contain: {', '.join(required_cols2)}\")\n",
    "\n",
    "# Convert timestamps to datetime and remove timezone\n",
    "df1['timestamp'] = pd.to_datetime(df1['timestamp'], errors='coerce').dt.tz_localize(None)\n",
    "df2['timestamp'] = pd.to_datetime(df2['timestamp'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Normalize pod names in df2 by taking the part before the first '-'\n",
    "df2['pod_normalized'] = df2['pod'].apply(lambda x: x.split('-')[0] if isinstance(x, str) and '-' in x else x)\n",
    "\n",
    "# Find common timestamps (exact match down to seconds)\n",
    "common_timestamps = sorted(set(df1['timestamp']).intersection(set(df2['timestamp'])))\n",
    "if not common_timestamps:\n",
    "    raise ValueError(\"No common timestamps found between the two datasets.\")\n",
    "\n",
    "# Collect all unique nodes (pods and instances)\n",
    "all_pods = set(df1['source_workload']).union(set(df1['destination_workload'])).union(set(df2['pod_normalized']))\n",
    "all_instances = set(df2['instance'])\n",
    "all_nodes = all_pods.union(all_instances)\n",
    "\n",
    "# Create a graph with all nodes to compute fixed positions\n",
    "G_all = nx.DiGraph()\n",
    "for node in all_nodes:\n",
    "    node_type = 'instance' if node in all_instances else 'pod'\n",
    "    G_all.add_node(node, type=node_type, label=node)\n",
    "\n",
    "# Compute fixed positions for all nodes\n",
    "fixed_pos = nx.spring_layout(G_all, seed=84, k=0.5, iterations=50)\n",
    "\n",
    "# Function to get edge color for pod-to-pod communication\n",
    "def get_communication_color(status):\n",
    "    return {\n",
    "        'Healthy': 'green',\n",
    "        'Degraded': 'blue',\n",
    "        'Unavailable': 'red'\n",
    "    }.get(status, 'gray')\n",
    "\n",
    "# Function to get edge color for instance-to-pod relationship\n",
    "def get_anomaly_color(abnormality_class):\n",
    "    return 'red' if abnormality_class != 'Normal' else 'green'\n",
    "\n",
    "# Function to build the combined graph for a given timestamp\n",
    "def build_combined_graph(timestamp):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Process pod-to-pod communications (from df1)\n",
    "    df1_window = df1[df1['timestamp'] == timestamp]\n",
    "    for _, row in df1_window.iterrows():\n",
    "        src = row['source_workload']\n",
    "        dst = row['destination_workload']\n",
    "        status = row['status']\n",
    "        score = row['anomaly_score']\n",
    "        color = get_communication_color(status)\n",
    "        label = f\"{score:.2f}\" if score > 0.0 else \"\"\n",
    "        \n",
    "        G.add_node(src, type='pod', label=src)\n",
    "        G.add_node(dst, type='pod', label=dst)\n",
    "        G.add_edge(src, dst, type='communication', color=color, label=label, score=score)\n",
    "    \n",
    "    # Process instance-to-pod relationships (from df2)\n",
    "    df2_window = df2[df2['timestamp'] == timestamp]\n",
    "    microservice_name = None\n",
    "    attack_type = None\n",
    "    anomaly_class = 'Normal'\n",
    "    attacked_pod = None  # Track the pod under attack\n",
    "    \n",
    "    for _, row in df2_window.iterrows():\n",
    "        instance = row['instance']\n",
    "        pod = row['pod_normalized']  # Use normalized pod name\n",
    "        abnormality = row['Abnormality class']\n",
    "        microservice = row['Microservice']\n",
    "        color = get_anomaly_color(abnormality)\n",
    "        \n",
    "        # If abnormality is not normal, extract the pod affected by the attack\n",
    "        if abnormality != 'Normal':\n",
    "            microservice_name, attack_type = microservice.split('_', 1)\n",
    "            attacked_pod = microservice_name  # The pod affected by the attack is the microservice part\n",
    "            \n",
    "        G.add_node(instance, type='instance', label=instance)\n",
    "        G.add_node(pod, type='pod', label=pod)\n",
    "        \n",
    "        # Add deployment edge; color it based on anomaly\n",
    "        if pod == attacked_pod:\n",
    "            # Color the edge red if the pod is attacked\n",
    "            G.add_edge(instance, pod, type='deployment', color='red', anomaly=abnormality)\n",
    "        else:\n",
    "            # Default color is green (normal)\n",
    "            G.add_edge(instance, pod, type='deployment', color='green', anomaly=abnormality)\n",
    "    \n",
    "    return G, microservice_name, attack_type, anomaly_class, attacked_pod\n",
    "\n",
    "# Initialize plot\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Animation update function\n",
    "def update(i):\n",
    "    ax.clear()\n",
    "    timestamp = common_timestamps[i]\n",
    "    G, microservice_name, attack_type, anomaly_class, attacked_pod = build_combined_graph(timestamp)\n",
    "    \n",
    "    # Draw nodes (pods as circles, instances as squares)\n",
    "    pod_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'pod']\n",
    "    instance_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'instance']\n",
    "    nx.draw_networkx_nodes(G, fixed_pos, nodelist=pod_nodes, node_size=600, node_color='skyblue', \n",
    "                          node_shape='o', ax=ax)\n",
    "    nx.draw_networkx_nodes(G, fixed_pos, nodelist=instance_nodes, node_size=600, node_color='lightgreen', \n",
    "                          node_shape='s', ax=ax)\n",
    "    \n",
    "    # Draw edges (communication as solid, deployment as dashed)\n",
    "    comm_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'communication']\n",
    "    deploy_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'deployment']\n",
    "\n",
    "    # Apply the same edge coloring logic for deployment edges\n",
    "    deploy_colors = [\n",
    "        'red' if (u, v) == (attacked_pod, v) or (u, v) == (u, attacked_pod) else 'green'\n",
    "        for u, v in deploy_edges\n",
    "    ]\n",
    "    \n",
    "    comm_colors = [G[u][v]['color'] for u, v in comm_edges]\n",
    "    \n",
    "    # Draw the edges\n",
    "    nx.draw_networkx_edges(G, fixed_pos, edgelist=comm_edges, edge_color=comm_colors, width=2, ax=ax)\n",
    "    nx.draw_networkx_edges(G, fixed_pos, edgelist=deploy_edges, edge_color=deploy_colors, width=2, \n",
    "                          style='dashed', ax=ax)\n",
    "    \n",
    "    # Draw node labels\n",
    "    nx.draw_networkx_labels(G, fixed_pos, labels=nx.get_node_attributes(G, 'label'), \n",
    "                           font_size=10, font_weight='bold', ax=ax)\n",
    "    \n",
    "    # Draw edge labels for communications\n",
    "    edge_labels = {(u, v): d['label'] for u, v, d in G.edges(data=True) \n",
    "                   if d['type'] == 'communication' and d['label']}\n",
    "    label_pos = {k: (v[0], v[1] + 0.03) for k, v in fixed_pos.items()}\n",
    "    nx.draw_networkx_edge_labels(G, pos=label_pos, edge_labels=edge_labels, \n",
    "                                font_size=9, font_color='black', ax=ax)\n",
    "    \n",
    "    # Legends\n",
    "    comm_legend = [\n",
    "        Line2D([0], [0], color='green', lw=2, label='Healthy'),\n",
    "        Line2D([0], [0], color='blue', lw=2, label='Degraded'),\n",
    "        Line2D([0], [0], color='red', lw=2, label='Unavailable')\n",
    "    ]\n",
    "    anomaly_legend = [\n",
    "        Line2D([0], [0], color='green', lw=2, linestyle='--', label='Normal'),\n",
    "        Line2D([0], [0], color='red', lw=2, linestyle='--', label='Anomaly')\n",
    "    ]\n",
    "    ax.legend(handles=comm_legend + anomaly_legend, loc='upper right')\n",
    "    \n",
    "    # Title with exact timestamp\n",
    "    ax.set_title(f\"Combined Graph for {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\", fontsize=14)\n",
    "    #if anomaly_class != 'Normal' and microservice_name:\n",
    "     #   plt.figtext(0.5, 0.01, f\"Microservice attaqu√© : {microservice_name}, Type : {attack_type.upper()}\",\n",
    "      #              wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    #else:\n",
    "     #   plt.figtext(0.5, 0.01, \"Aucune attaque d√©tect√©e\",\n",
    "      #              wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    ax.axis('off')\n",
    "\n",
    "# Create animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(common_timestamps), interval=1000, repeat=False)\n",
    "\n",
    "# Save as GIF\n",
    "ani.save('combined_graph6.gif', writer='pillow', fps=1)\n",
    "\n",
    "print(\"‚úÖ GIF saved as 'combined_graph6.gif'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0489baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nimport networkx as nx\\nimport matplotlib.pyplot as plt\\nfrom matplotlib.lines import Line2D\\nimport matplotlib.animation as animation\\nimport os\\n\\n# Load and preprocess data\\ndf1 = pd.read_csv(\"anomaly_scores_filtered.csv\")\\ndf2 = pd.read_csv(\"final2_modified_sorted.csv\")\\n\\n# Required columns\\nrequired_cols1 = [\\'source_workload\\', \\'destination_workload\\', \\'timestamp\\', \\'status\\', \\'anomaly_score\\']\\nrequired_cols2 = [\\'timestamp\\', \\'instance\\', \\'pod\\', \\'Abnormality class\\', \\'Microservice\\']\\nif not all(col in df1.columns for col in required_cols1):\\n    raise ValueError(f\"anomaly_scores_filtered.csv must contain: {\\', \\'.join(required_cols1)}\")\\nif not all(col in df2.columns for col in required_cols2):\\n    raise ValueError(f\"final2_modified_sorted.csv must contain: {\\', \\'.join(required_cols2)}\")\\n\\n# Convert timestamps to datetime and remove timezone\\ndf1[\\'timestamp\\'] = pd.to_datetime(df1[\\'timestamp\\'], errors=\\'coerce\\').dt.tz_localize(None)\\ndf2[\\'timestamp\\'] = pd.to_datetime(df2[\\'timestamp\\'], errors=\\'coerce\\').dt.tz_localize(None)\\n\\n# Normalize pod names in df2 by taking the part before the first \\'-\\'\\ndf2[\\'pod_normalized\\'] = df2[\\'pod\\'].apply(lambda x: x.split(\\'-\\')[0] if isinstance(x, str) and \\'-\\' in x else x)\\n\\n# Find common timestamps (exact match down to seconds)\\ncommon_timestamps = sorted(set(df1[\\'timestamp\\']).intersection(set(df2[\\'timestamp\\'])))\\nif not common_timestamps:\\n    raise ValueError(\"No common timestamps found between the two datasets.\")\\n\\n# Debug: Print common timestamps\\nprint(\"Common timestamps in both datasets:\")\\nfor ts in common_timestamps:\\n    print(ts)\\n\\n# Collect all unique nodes (pods and instances)\\nall_pods = set(df1[\\'source_workload\\']).union(set(df1[\\'destination_workload\\'])).union(set(df2[\\'pod_normalized\\']))\\nall_instances = set(df2[\\'instance\\'])\\nall_nodes = all_pods.union(all_instances)\\n\\n# Create a graph with all nodes to compute fixed positions\\nG_all = nx.DiGraph()\\nfor node in all_nodes:\\n    node_type = \\'instance\\' if node in all_instances else \\'pod\\'\\n    G_all.add_node(node, type=node_type, label=node)\\n\\n# Compute fixed positions for all nodes\\nfixed_pos = nx.spring_layout(G_all, seed=84, k=0.5, iterations=50)\\n\\n# Function to get edge color for pod-to-pod communication\\ndef get_communication_color(status):\\n    return {\\n        \\'Healthy\\': \\'green\\',\\n        \\'Degraded\\': \\'blue\\',\\n        \\'Unavailable\\': \\'red\\'\\n    }.get(status, \\'gray\\')\\n\\n# Function to build the combined graph for a given timestamp\\ndef build_combined_graph(timestamp):\\n    G = nx.DiGraph()\\n    \\n    # Process pod-to-pod communications (from df1)\\n    df1_window = df1[df1[\\'timestamp\\'] == timestamp]\\n    for _, row in df1_window.iterrows():\\n        src = row[\\'source_workload\\']\\n        dst = row[\\'destination_workload\\']\\n        status = row[\\'status\\']\\n        score = row[\\'anomaly_score\\']\\n        color = get_communication_color(status)\\n        label = f\"{score:.2f}\" if score > 0.0 else \"\"\\n        \\n        G.add_node(src, type=\\'pod\\', label=src)\\n        G.add_node(dst, type=\\'pod\\', label=dst)\\n        G.add_edge(src, dst, type=\\'communication\\', color=color, label=label, score=score)\\n    \\n    # Process instance-to-pod relationships (from df2)\\n    df2_window = df2[df2[\\'timestamp\\'] == timestamp]\\n    # Debug: Print df2_window contents\\n    print(f\"df2 window at {timestamp}:\\n\", df2_window[[\\'instance\\', \\'pod\\', \\'pod_normalized\\', \\'Microservice\\', \\'Abnormality class\\']])\\n    \\n    microservice_name = None\\n    attack_type = None\\n    has_anomaly = False\\n    \\n    for _, row in df2_window.iterrows():\\n        instance = row[\\'instance\\']\\n        pod = row[\\'pod_normalized\\']  # Use normalized pod name\\n        abnormality = row[\\'Abnormality class\\']\\n        microservice = row[\\'Microservice\\']\\n        \\n        # Default edge color is green\\n        edge_color = \\'green\\'\\n        edge_anomaly = \\'Normal\\'\\n        \\n        # Check for anomaly and update edge color and anomaly status\\n        try:\\n            microservice_name_temp, attack_type_temp = microservice.split(\\'_\\', 1)\\n            # Check if microservice_name_temp matches pod (case-insensitive partial match)\\n            if abnormality != \\'Normal\\' and microservice_name_temp.lower() in pod.lower():\\n                edge_color = \\'red\\'\\n                edge_anomaly = abnormality\\n                has_anomaly = True\\n                microservice_name = microservice_name_temp  # Update every time a red edge is added\\n                attack_type = attack_type_temp\\n                print(f\"Red edge added at {timestamp}: {instance} -> {pod}, microservice={microservice_name_temp}, attack_type={attack_type_temp}, abnormality={abnormality}\")\\n        except:\\n            microservice_name_temp = microservice\\n            attack_type_temp = \\'\\'\\n            if abnormality != \\'Normal\\' and microservice_name_temp.lower() in pod.lower():\\n                edge_color = \\'red\\'\\n                edge_anomaly = abnormality\\n                has_anomaly = True\\n                microservice_name = microservice_name_temp  # Update every time a red edge is added\\n                attack_type = attack_type_temp\\n                print(f\"Red edge added at {timestamp}: {instance} -> {pod}, microservice={microservice_name_temp}, attack_type={attack_type_temp}, abnormality={abnormality}\")\\n        \\n        G.add_node(instance, type=\\'instance\\', label=instance)\\n        G.add_node(pod, type=\\'pod\\', label=pod)\\n        G.add_edge(instance, pod, type=\\'deployment\\', color=edge_color, anomaly=edge_anomaly)\\n    \\n    # Debug: Final state before return\\n    print(f\"Returning from build_combined_graph at {timestamp}: has_anomaly={has_anomaly}, microservice_name={microservice_name}, attack_type={attack_type}\")\\n    \\n    return G, microservice_name, attack_type, has_anomaly\\n\\n# Initialize plot\\nfig, ax = plt.subplots(figsize=(20, 10))\\n\\n# Animation update function\\ndef update(i):\\n    ax.clear()\\n    timestamp = common_timestamps[i]\\n    G, microservice_name, attack_type, has_anomaly = build_combined_graph(timestamp)\\n    \\n    # Debug: Print current timestamp and anomaly status\\n    print(f\"Processing timestamp: {timestamp}, has_anomaly={has_anomaly}, microservice_name={microservice_name}\")\\n    \\n    # Draw nodes (pods as circles, instances as squares)\\n    pod_nodes = [n for n, d in G.nodes(data=True) if d[\\'type\\'] == \\'pod\\']\\n    instance_nodes = [n for n, d in G.nodes(data=True) if d[\\'type\\'] == \\'instance\\']\\n    nx.draw_networkx_nodes(G, fixed_pos, nodelist=pod_nodes, node_size=600, node_color=\\'skyblue\\', \\n                          node_shape=\\'o\\', ax=ax)\\n    nx.draw_networkx_nodes(G, fixed_pos, nodelist=instance_nodes, node_size=600, node_color=\\'lightgreen\\', \\n                          node_shape=\\'s\\', ax=ax)\\n    \\n    # Draw edges (communication as solid, deployment as dashed)\\n    comm_edges = [(u, v) for u, v, d in G.edges(data=True) if d[\\'type\\'] == \\'communication\\']\\n    deploy_edges = [(u, v) for u, v, d in G.edges(data=True) if d[\\'type\\'] == \\'deployment\\']\\n    comm_colors = [G[u][v][\\'color\\'] for u, v in comm_edges]\\n    deploy_colors = [G[u][v][\\'color\\'] for u, v in deploy_edges]\\n    nx.draw_networkx_edges(G, fixed_pos, edgelist=comm_edges, edge_color=comm_colors, width=2, ax=ax)\\n    nx.draw_networkx_edges(G, fixed_pos, edgelist=deploy_edges, edge_color=deploy_colors, width=2, \\n                          style=\\'dashed\\', ax=ax)\\n    \\n    # Draw node labels\\n    nx.draw_networkx_labels(G, fixed_pos, labels=nx.get_node_attributes(G, \\'label\\'), \\n                           font_size=10, font_weight=\\'bold\\', ax=ax)\\n    \\n    # Draw edge labels for communications\\n    edge_labels = {(u, v): d[\\'label\\'] for u, v, d in G.edges(data=True) \\n                   if d[\\'type\\'] == \\'communication\\' and d[\\'label\\']}\\n    label_pos = {k: (v[0], v[1] + 0.03) for k, v in fixed_pos.items()}\\n    nx.draw_networkx_edge_labels(G, pos=label_pos, edge_labels=edge_labels, \\n                                font_size=9, font_color=\\'black\\', ax=ax)\\n    \\n    # Legends\\n    comm_legend = [\\n        Line2D([0], [0], color=\\'green\\', lw=2, label=\\'Healthy\\'),\\n        Line2D([0], [0], color=\\'blue\\', lw=2, label=\\'Degraded\\'),\\n        Line2D([0], [0], color=\\'red\\', lw=2, label=\\'Unavailable\\')\\n    ]\\n    anomaly_legend = [\\n        Line2D([0], [0], color=\\'green\\', lw=2, linestyle=\\'--\\', label=\\'Normal\\'),\\n        Line2D([0], [0], color=\\'red\\', lw=2, linestyle=\\'--\\', label=\\'Anomaly\\')\\n    ]\\n    ax.legend(handles=comm_legend + anomaly_legend, loc=\\'upper right\\')\\n    \\n    # Title with exact timestamp\\n    ax.set_title(f\"Combined Graph for {timestamp.strftime(\\'%Y-%m-%d %H:%M:%S\\')}\", fontsize=14)\\n    \\n    # Display attack information if anomaly detected\\n    if has_anomaly:\\n        plt.figtext(0.5, 0.01, f\"Microservice attaqu√© : {microservice_name or \\'UNKNOWN\\'}, Type : {attack_type.upper() if attack_type else \\'UNKNOWN\\'}\",\\n                    wrap=True, horizontalalignment=\\'center\\', fontsize=12)\\n    else:\\n        plt.figtext(0.5, 0.01, \"Aucune attaque d√©tect√©e\",\\n                    wrap=True, horizontalalignment=\\'center\\', fontsize=12)\\n    \\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\\n    ax.axis(\\'off\\')\\n    \\n    # Display the plot in Visual Studio Code\\n    plt.show()\\n\\n# Create animation\\nani = animation.FuncAnimation(fig, update, frames=len(common_timestamps), interval=1000, repeat=False)\\n\\n# Save as GIF\\nani.save(\\'combined_graph7.gif\\', writer=\\'pillow\\', fps=1)\\n\\nprint(\"‚úÖ GIF saved as \\'combined_graph7.gif\\'\")\\nplt.close()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "\n",
    "# Load and preprocess data\n",
    "df1 = pd.read_csv(\"anomaly_scores_filtered.csv\")\n",
    "df2 = pd.read_csv(\"final2_modified_sorted.csv\")\n",
    "\n",
    "# Required columns\n",
    "required_cols1 = ['source_workload', 'destination_workload', 'timestamp', 'status', 'anomaly_score']\n",
    "required_cols2 = ['timestamp', 'instance', 'pod', 'Abnormality class', 'Microservice']\n",
    "if not all(col in df1.columns for col in required_cols1):\n",
    "    raise ValueError(f\"anomaly_scores_filtered.csv must contain: {', '.join(required_cols1)}\")\n",
    "if not all(col in df2.columns for col in required_cols2):\n",
    "    raise ValueError(f\"final2_modified_sorted.csv must contain: {', '.join(required_cols2)}\")\n",
    "\n",
    "# Convert timestamps to datetime and remove timezone\n",
    "df1['timestamp'] = pd.to_datetime(df1['timestamp'], errors='coerce').dt.tz_localize(None)\n",
    "df2['timestamp'] = pd.to_datetime(df2['timestamp'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Normalize pod names in df2 by taking the part before the first '-'\n",
    "df2['pod_normalized'] = df2['pod'].apply(lambda x: x.split('-')[0] if isinstance(x, str) and '-' in x else x)\n",
    "\n",
    "# Find common timestamps (exact match down to seconds)\n",
    "common_timestamps = sorted(set(df1['timestamp']).intersection(set(df2['timestamp'])))\n",
    "if not common_timestamps:\n",
    "    raise ValueError(\"No common timestamps found between the two datasets.\")\n",
    "\n",
    "# Debug: Print common timestamps\n",
    "print(\"Common timestamps in both datasets:\")\n",
    "for ts in common_timestamps:\n",
    "    print(ts)\n",
    "\n",
    "# Collect all unique nodes (pods and instances)\n",
    "all_pods = set(df1['source_workload']).union(set(df1['destination_workload'])).union(set(df2['pod_normalized']))\n",
    "all_instances = set(df2['instance'])\n",
    "all_nodes = all_pods.union(all_instances)\n",
    "\n",
    "# Create a graph with all nodes to compute fixed positions\n",
    "G_all = nx.DiGraph()\n",
    "for node in all_nodes:\n",
    "    node_type = 'instance' if node in all_instances else 'pod'\n",
    "    G_all.add_node(node, type=node_type, label=node)\n",
    "\n",
    "# Compute fixed positions for all nodes\n",
    "fixed_pos = nx.spring_layout(G_all, seed=84, k=0.5, iterations=50)\n",
    "\n",
    "# Function to get edge color for pod-to-pod communication\n",
    "def get_communication_color(status):\n",
    "    return {\n",
    "        'Healthy': 'green',\n",
    "        'Degraded': 'blue',\n",
    "        'Unavailable': 'red'\n",
    "    }.get(status, 'gray')\n",
    "\n",
    "# Function to build the combined graph for a given timestamp\n",
    "def build_combined_graph(timestamp):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Process pod-to-pod communications (from df1)\n",
    "    df1_window = df1[df1['timestamp'] == timestamp]\n",
    "    for _, row in df1_window.iterrows():\n",
    "        src = row['source_workload']\n",
    "        dst = row['destination_workload']\n",
    "        status = row['status']\n",
    "        score = row['anomaly_score']\n",
    "        color = get_communication_color(status)\n",
    "        label = f\"{score:.2f}\" if score > 0.0 else \"\"\n",
    "        \n",
    "        G.add_node(src, type='pod', label=src)\n",
    "        G.add_node(dst, type='pod', label=dst)\n",
    "        G.add_edge(src, dst, type='communication', color=color, label=label, score=score)\n",
    "    \n",
    "    # Process instance-to-pod relationships (from df2)\n",
    "    df2_window = df2[df2['timestamp'] == timestamp]\n",
    "    # Debug: Print df2_window contents\n",
    "    print(f\"df2 window at {timestamp}:\\n\", df2_window[['instance', 'pod', 'pod_normalized', 'Microservice', 'Abnormality class']])\n",
    "    \n",
    "    microservice_name = None\n",
    "    attack_type = None\n",
    "    has_anomaly = False\n",
    "    \n",
    "    for _, row in df2_window.iterrows():\n",
    "        instance = row['instance']\n",
    "        pod = row['pod_normalized']  # Use normalized pod name\n",
    "        abnormality = row['Abnormality class']\n",
    "        microservice = row['Microservice']\n",
    "        \n",
    "        # Default edge color is green\n",
    "        edge_color = 'green'\n",
    "        edge_anomaly = 'Normal'\n",
    "        \n",
    "        # Check for anomaly and update edge color and anomaly status\n",
    "        try:\n",
    "            microservice_name_temp, attack_type_temp = microservice.split('_', 1)\n",
    "            # Check if microservice_name_temp matches pod (case-insensitive partial match)\n",
    "            if abnormality != 'Normal' and microservice_name_temp.lower() in pod.lower():\n",
    "                edge_color = 'red'\n",
    "                edge_anomaly = abnormality\n",
    "                has_anomaly = True\n",
    "                microservice_name = microservice_name_temp  # Update every time a red edge is added\n",
    "                attack_type = attack_type_temp\n",
    "                print(f\"Red edge added at {timestamp}: {instance} -> {pod}, microservice={microservice_name_temp}, attack_type={attack_type_temp}, abnormality={abnormality}\")\n",
    "        except:\n",
    "            microservice_name_temp = microservice\n",
    "            attack_type_temp = ''\n",
    "            if abnormality != 'Normal' and microservice_name_temp.lower() in pod.lower():\n",
    "                edge_color = 'red'\n",
    "                edge_anomaly = abnormality\n",
    "                has_anomaly = True\n",
    "                microservice_name = microservice_name_temp  # Update every time a red edge is added\n",
    "                attack_type = attack_type_temp\n",
    "                print(f\"Red edge added at {timestamp}: {instance} -> {pod}, microservice={microservice_name_temp}, attack_type={attack_type_temp}, abnormality={abnormality}\")\n",
    "        \n",
    "        G.add_node(instance, type='instance', label=instance)\n",
    "        G.add_node(pod, type='pod', label=pod)\n",
    "        G.add_edge(instance, pod, type='deployment', color=edge_color, anomaly=edge_anomaly)\n",
    "    \n",
    "    # Debug: Final state before return\n",
    "    print(f\"Returning from build_combined_graph at {timestamp}: has_anomaly={has_anomaly}, microservice_name={microservice_name}, attack_type={attack_type}\")\n",
    "    \n",
    "    return G, microservice_name, attack_type, has_anomaly\n",
    "\n",
    "# Initialize plot\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Animation update function\n",
    "def update(i):\n",
    "    ax.clear()\n",
    "    timestamp = common_timestamps[i]\n",
    "    G, microservice_name, attack_type, has_anomaly = build_combined_graph(timestamp)\n",
    "    \n",
    "    # Debug: Print current timestamp and anomaly status\n",
    "    print(f\"Processing timestamp: {timestamp}, has_anomaly={has_anomaly}, microservice_name={microservice_name}\")\n",
    "    \n",
    "    # Draw nodes (pods as circles, instances as squares)\n",
    "    pod_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'pod']\n",
    "    instance_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'instance']\n",
    "    nx.draw_networkx_nodes(G, fixed_pos, nodelist=pod_nodes, node_size=600, node_color='skyblue', \n",
    "                          node_shape='o', ax=ax)\n",
    "    nx.draw_networkx_nodes(G, fixed_pos, nodelist=instance_nodes, node_size=600, node_color='lightgreen', \n",
    "                          node_shape='s', ax=ax)\n",
    "    \n",
    "    # Draw edges (communication as solid, deployment as dashed)\n",
    "    comm_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'communication']\n",
    "    deploy_edges = [(u, v) for u, v, d in G.edges(data=True) if d['type'] == 'deployment']\n",
    "    comm_colors = [G[u][v]['color'] for u, v in comm_edges]\n",
    "    deploy_colors = [G[u][v]['color'] for u, v in deploy_edges]\n",
    "    nx.draw_networkx_edges(G, fixed_pos, edgelist=comm_edges, edge_color=comm_colors, width=2, ax=ax)\n",
    "    nx.draw_networkx_edges(G, fixed_pos, edgelist=deploy_edges, edge_color=deploy_colors, width=2, \n",
    "                          style='dashed', ax=ax)\n",
    "    \n",
    "    # Draw node labels\n",
    "    nx.draw_networkx_labels(G, fixed_pos, labels=nx.get_node_attributes(G, 'label'), \n",
    "                           font_size=10, font_weight='bold', ax=ax)\n",
    "    \n",
    "    # Draw edge labels for communications\n",
    "    edge_labels = {(u, v): d['label'] for u, v, d in G.edges(data=True) \n",
    "                   if d['type'] == 'communication' and d['label']}\n",
    "    label_pos = {k: (v[0], v[1] + 0.03) for k, v in fixed_pos.items()}\n",
    "    nx.draw_networkx_edge_labels(G, pos=label_pos, edge_labels=edge_labels, \n",
    "                                font_size=9, font_color='black', ax=ax)\n",
    "    \n",
    "    # Legends\n",
    "    comm_legend = [\n",
    "        Line2D([0], [0], color='green', lw=2, label='Healthy'),\n",
    "        Line2D([0], [0], color='blue', lw=2, label='Degraded'),\n",
    "        Line2D([0], [0], color='red', lw=2, label='Unavailable')\n",
    "    ]\n",
    "    anomaly_legend = [\n",
    "        Line2D([0], [0], color='green', lw=2, linestyle='--', label='Normal'),\n",
    "        Line2D([0], [0], color='red', lw=2, linestyle='--', label='Anomaly')\n",
    "    ]\n",
    "    ax.legend(handles=comm_legend + anomaly_legend, loc='upper right')\n",
    "    \n",
    "    # Title with exact timestamp\n",
    "    ax.set_title(f\"Combined Graph for {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\", fontsize=14)\n",
    "    \n",
    "    # Display attack information if anomaly detected\n",
    "    if has_anomaly:\n",
    "        plt.figtext(0.5, 0.01, f\"Microservice attaqu√© : {microservice_name or 'UNKNOWN'}, Type : {attack_type.upper() if attack_type else 'UNKNOWN'}\",\n",
    "                    wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    else:\n",
    "        plt.figtext(0.5, 0.01, \"Aucune attaque d√©tect√©e\",\n",
    "                    wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Display the plot in Visual Studio Code\n",
    "    plt.show()\n",
    "\n",
    "# Create animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(common_timestamps), interval=1000, repeat=False)\n",
    "\n",
    "# Save as GIF\n",
    "ani.save('combined_graph7.gif', writer='pillow', fps=1)\n",
    "\n",
    "print(\"‚úÖ GIF saved as 'combined_graph7.gif'\")\n",
    "plt.close()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
